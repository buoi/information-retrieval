{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-SQuAD-squad/IR/blob/electra/IR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QeSehvkoMtT"
      },
      "source": [
        "DA FARE: \r\n",
        "-Sistemare dataset in modo che le coppie domanda passaggio siano giuste\r\n",
        "-Provare modello dense, senza trainare Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFibP1RFJ2jZ",
        "outputId": "1be21a7a-8df2-4fab-9704-d344ca0f4188"
      },
      "source": [
        "#@title Init { form-width: \"25%\" }\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "!pip install tokenizers\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "# fix random seeds\n",
        "seed_value = 42 #@param {type:\"integer\"}\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "tf.compat.v1.set_random_seed(seed_value)\n",
        "\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "# BERT params\n",
        "max_seq_length = 512\n",
        "# Huggingface bert and associated tokenizer\n",
        "pretrained_model_str = \"google/electra-small-discriminator\"\n",
        "bert_hf_layer = transformers.TFElectraModel.from_pretrained(\n",
        "    pretrained_model_str, output_attentions=True)\n",
        "\n",
        "#pretrained_model_str = \"roberta-base\"\n",
        "#bert_hf_layer = transformers.TFRobertaModel.from_pretrained(\n",
        "    #pretrained_model_str, output_attentions=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_str)\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "Some layers from the model checkpoint at google/electra-small-discriminator were not used when initializing TFElectraModel: ['discriminator_predictions']\n",
            "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-small-discriminator.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 24 11:54:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    36W / 250W |    643MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUGjp7aOKRyW",
        "outputId": "fab9ab2c-0855-44de-b74e-0dc30f8bdb33"
      },
      "source": [
        "#@title df creation { form-width: \"25%\" }\n",
        "\n",
        "# the official dataset is identical to the provided one\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json -O training_set.json\n",
        "\n",
        "with open(\"training_set.json\", \"r\") as f:\n",
        "    json_file = json.load(f)\n",
        "data = json_file[\"data\"]\n",
        "\n",
        "rows = []\n",
        "for document in data:\n",
        "  for par in document['paragraphs']:\n",
        "    for qas in par['qas']:\n",
        "      rows.append({\n",
        "        'id' : qas['id'],\n",
        "        'title': document[\"title\"],\n",
        "        'passage': par['context'],\n",
        "        'question' : qas['question'],\n",
        "        'answer_idx' : (qas['answers'][0]['answer_start'], \n",
        "                    qas['answers'][0]['answer_start'] + len(qas['answers'][0]['text'])),\n",
        "        'answer_text' : qas['answers'][0]['text']\n",
        "      })\n",
        "\n",
        "df_original = pd.DataFrame(rows)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-24 11:54:40--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.110.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: ‘training_set.json’\n",
            "\n",
            "training_set.json   100%[===================>]  28.88M   106MB/s    in 0.3s    \n",
            "\n",
            "2021-02-24 11:54:41 (106 MB/s) - ‘training_set.json’ saved [30288272/30288272]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "ssgBa3_tKpM8",
        "outputId": "8d8835a7-9e99-4b43-ef4a-5349ab761107"
      },
      "source": [
        "#@title clean dataset { form-width: \"25%\" }\n",
        "\n",
        "!gcloud config set project feisty-mechanic-221914\n",
        "!gsutil cp gs://squad_squad/error_IDs.txt ./error_IDs.txt\n",
        "\n",
        "with open(\"error_IDs.txt\", \"r\") as f:\n",
        "    unwanted_id = f.read()\n",
        "\n",
        "unwanted_id = unwanted_id.split(\"\\n\")[:-1]\n",
        "df_bert = df_original.set_index('id')\n",
        "df_bert = df_bert.drop(unwanted_id)\n",
        "df_bert.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Copying gs://squad_squad/error_IDs.txt...\n",
            "/ [1 files][  5.7 KiB/  5.7 KiB]                                                \n",
            "Operation completed over 1 objects/5.7 KiB.                                      \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_idx</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661182</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
              "      <td>(515, 541)</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117f</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>(188, 213)</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661180</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame is beside to which structure?</td>\n",
              "      <td>(279, 296)</td>\n",
              "      <td>the Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661181</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>(381, 420)</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117e</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>What sits on top of the Main Building at Notre Dame?</td>\n",
              "      <td>(92, 126)</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             title  ...                              answer_text\n",
              "id                                                  ...                                         \n",
              "5733be284776f41900661182  University_of_Notre_Dame  ...  Saint Bernadette Soubirous             \n",
              "5733be284776f4190066117f  University_of_Notre_Dame  ...  a copper statue of Christ              \n",
              "5733be284776f41900661180  University_of_Notre_Dame  ...  the Main Building                      \n",
              "5733be284776f41900661181  University_of_Notre_Dame  ...  a Marian place of prayer and reflection\n",
              "5733be284776f4190066117e  University_of_Notre_Dame  ...  a golden statue of the Virgin Mary     \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "3NmgPXxseEZy",
        "outputId": "1f2e7803-5833-4fb3-f3fd-d1fea7372372"
      },
      "source": [
        "#@title BERT preprocessing { form-width: \"25%\" }\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "def preprocess_bert(text):\r\n",
        "    tokenized_text = tokenizer(list(text), padding=\"max_length\", max_length=max_seq_length, truncation=True)\r\n",
        "    return tokenized_text.input_ids\r\n",
        "\r\n",
        "df_bert_preprocessed = df_bert.copy()\r\n",
        "# pre-process passage and question text\r\n",
        "print(\"Preprocessing passage...\")\r\n",
        "df_bert_preprocessed['passage'] = preprocess_bert(df_bert['passage'])\r\n",
        "print(\"Preprocessing question...\")\r\n",
        "df_bert_preprocessed['question'] = preprocess_bert(df_bert['question'])\r\n",
        "df_bert_preprocessed.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing passage...\n",
            "Preprocessing question...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_idx</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661182</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(515, 541)</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117f</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2054, 2003, 1999, 2392, 1997, 1996, 10289, 8214, 2364, 2311, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(188, 213)</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661180</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 1996, 13546, 1997, 1996, 6730, 2540, 2012, 10289, 8214, 2003, 3875, 2000, 2029, 3252, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(279, 296)</td>\n",
              "      <td>the Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661181</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2054, 2003, 1996, 24665, 23052, 2012, 10289, 8214, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(381, 420)</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117e</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2054, 7719, 2006, 2327, 1997, 1996, 2364, 2311, 2012, 10289, 8214, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(92, 126)</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             title  ...                              answer_text\n",
              "id                                                  ...                                         \n",
              "5733be284776f41900661182  University_of_Notre_Dame  ...  Saint Bernadette Soubirous             \n",
              "5733be284776f4190066117f  University_of_Notre_Dame  ...  a copper statue of Christ              \n",
              "5733be284776f41900661180  University_of_Notre_Dame  ...  the Main Building                      \n",
              "5733be284776f41900661181  University_of_Notre_Dame  ...  a Marian place of prayer and reflection\n",
              "5733be284776f4190066117e  University_of_Notre_Dame  ...  a golden statue of the Virgin Mary     \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pYmLh3E31ox",
        "outputId": "31e85e7e-3415-4a6a-9bee-e8e6300dd1ba"
      },
      "source": [
        "list(df_bert.groupby('passage').groups.keys())[100:200]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['23rd Street is another main numbered street in Manhattan. It begins at FDR Drive and ends at Eleventh Avenue. Its length is 3.1 km/1.9m. It has two-way travel. On 23rd Street there are five local subway stations:',\n",
              " '24th Street is in two parts. 24th Street starts at First Avenue and it ends at Madison Avenue, because of Madison Square Park. 25th Street, which is in three parts, starts at FDR Drive, is a pedestrian plaza between Third Avenue and Lexington Avenue, and ends at Madison. Then West 24th and 25th Streets continue from Fifth Avenue to Eleventh Avenue (25th) or Twelfth Avenue (24th).',\n",
              " \"26 March 1991 is the day that marks the clash between military soldiers and peaceful demonstrating students which climaxed in the massacre of dozens under the orders of then President Moussa Traoré. He and three associates were later tried and convicted and received the death sentence for their part in the decision-making of that day. Nowadays, the day is a national holiday in order to remember the tragic events and the people that were killed.[unreliable source?] The coup is remembered as Mali's March Revolution of 1991.\",\n",
              " '27th Street is a one-way street runs from Second Avenue to the West Side Highway with an interruption between Eighth Avenue and Tenth Avenue. It is most noted for its strip between Tenth and Eleventh Avenues, known as Club Row because it features numerous nightclubs and lounges.',\n",
              " '3 kV DC is used in Belgium, Italy, Spain, Poland, the northern Czech Republic, Slovakia, Slovenia, South Africa, Chile, and former Soviet Union countries (also using 25 kV 50 Hz AC). It was formerly used by the Milwaukee Road from Harlowton, Montana to Seattle-Tacoma, across the Continental Divide and including extensive branch and loop lines in Montana, and by the Delaware, Lackawanna & Western Railroad (now New Jersey Transit, converted to 25 kV AC) in the United States, and the Kolkata suburban railway (Bardhaman Main Line) in India, before it was converted to 25 kV 50 Hz AC.',\n",
              " \"31st Street begins on the West Side at the West Side Yard, while 32nd Street, which includes a segment officially known as Korea Way between Fifth Avenue and Broadway in Manhattan's Koreatown, begins at the entrance to Penn Station and Madison Square Garden. On the East Side, both streets end at Second Avenue at Kips Bay Towers and NYU Medical Center which occupy the area between 30th and 34th Streets. The Catholic church of St. Francis of Assisi is situated at 135–139 West 31st Street. At 210 West is the Capuchin Monastery of St. John the Baptist, part of St. John the Baptist Church on 30th Street. At the corner of Broadway and West 31st Street is the Grand Hotel. The former Hotel Pierrepont was located at 43 West 32nd Street, The Continental NYC tower is at the corner of Sixth Avenue and 32nd Street. 29 East 32nd Street was the location of the first building owned by the Grolier Club between 1890 and 1917.\",\n",
              " '35th Street runs from FDR Drive to Eleventh Avenue. Notable locations include East River Ferry, LaptopMD headquarters, Mercy College Manhattan Campus, and Jacob K. Javits Convention Center.',\n",
              " \"40°48′27″N 73°57′18″W\\ufeff / \\ufeff40.8076°N 73.9549°W\\ufeff / 40.8076; -73.9549 120th Street traverses the neighborhoods of Morningside Heights, Harlem, and Spanish Harlem. It begins on Riverside Drive at the Interchurch Center. It then runs east between the campuses of Barnard College and the Union Theological Seminary, then crosses Broadway and runs between the campuses of Columbia University and Teacher's College. The street is interrupted by Morningside Park. It then continues east, eventually running along the southern edge of Marcus Garvey Park, passing by 58 West, the former residence of Maya Angelou. It then continues through Spanish Harlem; when it crosses Pleasant Avenue it becomes a two‑way street and continues nearly to the East River, where for automobiles, it turns north and becomes Paladino Avenue, and for pedestrians, continues as a bridge across FDR Drive.\",\n",
              " '40°48′32″N 73°57′14″W\\ufeff / \\ufeff40.8088°N 73.9540°W\\ufeff / 40.8088; -73.9540 122nd Street is divided into three noncontiguous segments, E 122nd Street, W 122nd Street, and W 122nd Street Seminary Row, by Marcus Garvey Memorial Park and Morningside Park.',\n",
              " '40°48′47″N 73°57′27″W\\ufeff / \\ufeff40.813°N 73.9575°W\\ufeff / 40.813; -73.9575 La Salle Street is a street in West Harlem that runs just two blocks between Amsterdam Avenue and Claremont Avenue. West of Convent Avenue, 125th Street was re-routed onto the old Manhattan Avenue. The original 125th Street west of Convent Avenue was swallowed up to make the super-blocks where the low income housing projects now exist. La Salle Street is the only vestige of the original routing.',\n",
              " '40°48′52″N 73°56′53″W\\ufeff / \\ufeff40.814583°N 73.947944°W\\ufeff / 40.814583; -73.947944 132nd Street runs east-west above Central Park and is located in Harlem just south of Hamilton Heights. The main portion of 132nd Street runs eastbound from Frederick Douglass Boulevard to northern end of Park Avenue where there is a southbound exit from/entrance to the Harlem River Drive. After an interruption from St. Nicholas Park and City College, there is another small stretch of West 132nd Street between Broadway and Twelfth Avenue',\n",
              " \"48 of Switzerland's mountains are 4,000 metres (13,000 ft) above sea in altitude or higher. At 4,634 m (15,203 ft), Monte Rosa is the highest, although the Matterhorn (4,478 m or 14,692 ft) is often regarded as the most famous. Both are located within the Pennine Alps in the canton of Valais. The section of the Bernese Alps above the deep glacial Lauterbrunnen valley, containing 72 waterfalls, is well known for the Jungfrau (4,158 m or 13,642 ft) Eiger and Mönch, and the many picturesque valleys in the region. In the southeast the long Engadin Valley, encompassing the St. Moritz area in canton of Graubünden, is also well known; the highest peak in the neighbouring Bernina Alps is Piz Bernina (4,049 m or 13,284 ft).\",\n",
              " '50 Hz systems support three scanning rates: 50i, 25p and 50p. 60 Hz systems support a much wider set of frame rates: 59.94i, 60i, 23.976p, 24p, 29.97p, 30p, 59.94p and 60p. In the days of standard definition television, the fractional rates were often rounded up to whole numbers, e.g. 23.976p was often called 24p, or 59.94i was often called 60i. 60 Hz high definition television supports both fractional and slightly different integer rates, therefore strict usage of notation is required to avoid ambiguity. Nevertheless, 29.97i/59.94i is almost universally called 60i, likewise 23.976p is called 24p.',\n",
              " '58.1% of the population described themselves in the 2011 census return as being at least nominally Christian and 0.8% as Muslim with all other religions represented by less than 0.5% each. The portion of people without a religion is 32.9%; above the national average of 24.7%. 7.1% did not state their religious belief. Since the 2001 Census, the number of Christians and Jews has decreased (-16% and -7% respectively), while all other religions have increased and non-religious people have almost doubled in number.',\n",
              " '630 people lost their lives as a result of the air raids on Southampton and nearly 2,000 more were injured, not to mention the thousands of buildings damaged or destroyed.',\n",
              " \"64Zn, the most abundant isotope of zinc, is very susceptible to neutron activation, being transmuted into the highly radioactive 65Zn, which has a half-life of 244 days and produces intense gamma radiation. Because of this, Zinc Oxide used in nuclear reactors as an anti-corrosion agent is depleted of 64Zn before use, this is called depleted zinc oxide. For the same reason, zinc has been proposed as a salting material for nuclear weapons (cobalt is another, better-known salting material). A jacket of isotopically enriched 64Zn would be irradiated by the intense high-energy neutron flux from an exploding thermonuclear weapon, forming a large amount of 65Zn significantly increasing the radioactivity of the weapon's fallout. Such a weapon is not known to have ever been built, tested, or used. 65Zn is also used as a tracer to study how alloys that contain zinc wear out, or the path and the role of zinc in organisms.\",\n",
              " '6th-century BCE pre-Socratic Greek philosophers Thales of Miletus and Xenophanes of Colophon were the first in the region to attempt to explain the world in terms of human reason rather than myth and tradition, thus can be said to be the first Greek humanists. Thales questioned the notion of anthropomorphic gods and Xenophanes refused to recognise the gods of his time and reserved the divine for the principle of unity in the universe. These Ionian Greeks were the first thinkers to assert that nature is available to be studied separately from the supernatural realm. Anaxagoras brought philosophy and the spirit of rational inquiry from Ionia to Athens. Pericles, the leader of Athens during the period of its greatest glory was an admirer of Anaxagoras. Other influential pre-Socratics or rational philosophers include Protagoras (like Anaxagoras a friend of Pericles), known for his famous dictum \"man is the measure of all things\" and Democritus, who proposed that matter was composed of atoms. Little of the written work of these early philosophers survives and they are known mainly from fragments and quotations in other writers, principally Plato and Aristotle. The historian Thucydides, noted for his scientific and rational approach to history, is also much admired by later humanists. In the 3rd century BCE, Epicurus became known for his concise phrasing of the problem of evil, lack of belief in the afterlife, and human-centred approaches to achieving eudaimonia. He was also the first Greek philosopher to admit women to his school as a rule.',\n",
              " '808s & Heartbreak, which features extensive use of the eponymous Roland TR-808 drum machine and contains themes of love, loneliness, and heartache, was released by Island Def Jam to capitalize on Thanksgiving weekend in November 2008. Reviews were positive, though slightly more mixed than his previous efforts. Despite this, the record\\'s singles demonstrated outstanding chart performances. Upon its release, the lead single \"Love Lockdown\" debuted at number three on the Billboard Hot 100 and became a \"Hot Shot Debut\", while follow-up single \"Heartless\" performed similarly and became his second consecutive \"Hot Shot Debut\" by debuting at number four on the Billboard Hot 100. While it was criticized prior to release, 808s & Heartbreak had a significant effect on hip-hop music, encouraging other rappers to take more creative risks with their productions.',\n",
              " \"83% of the total population adheres to Christianity, making it the most common religion in Swaziland. Anglican, Protestant and indigenous African churches, including African Zionist, constitute the majority of the Christians (40%), followed by Roman Catholicism at 20% of the population. On 18 July 2012, Ellinah Wamukoya, was elected Anglican Bishop of Swaziland, becoming the first woman to be a bishop in Africa. 15% of the population follows traditional religions; other non-Christian religions practised in the country include Islam (1%), the Bahá'í Faith (0.5%), and Hinduism (0.2%). There are 14 Jewish families.\",\n",
              " \"8th and 9th Streets run parallel to each other, beginning at Avenue D, interrupted by Tompkins Square Park at Avenue B, resuming at Avenue A and continuing to Sixth Avenue. West 8th Street is an important local shopping street. 8th Street between Avenue A and Third Avenue is called St Mark's Place, but it is counted in the length below.\",\n",
              " '90th Street is split into two segments. The first segment, West 90th Street begins at Riverside Drive and ends at Central Park West or West Drive, when it is open, in Central Park on the Upper West Side. The second segment of East 90th Street begins at East Drive, at Engineers Gate of Central Park. When East Drive is closed, East 90th Street begins at Fifth Avenue on the Upper East Side and curves to the right at the FDR Drive becoming East End Avenue. Our Lady of Good Counsel Church, is located on East 90th Street between Third Avenue and Second Avenue, across the street from Ruppert Towers (1601 and 1619 Third Avenue) and Ruppert Park. Asphalt Green, which is located on East 90th Street between York Avenue and East End Avenue.',\n",
              " 'A \"beer engine\" is a device for pumping beer, originally manually operated and typically used to dispense beer from a cask or container in a pub\\'s basement or cellar.',\n",
              " 'A \"country pub\" by tradition is a rural public house. However, the distinctive culture surrounding country pubs, that of functioning as a social centre for a village and rural community, has been changing over the last thirty or so years. In the past, many rural pubs provided opportunities for country folk to meet and exchange (often local) news, while others—especially those away from village centres—existed for the general purpose, before the advent of motor transport, of serving travellers as coaching inns.',\n",
              " 'A \"grand\", sometimes shortened to simply \"G\", is a common term for the amount of $1,000. The suffix \"K\" or \"k\" (from \"kilo-\") is also commonly used to denote this amount (such as \"$10k\" to mean $10,000). However, the $1,000 note is no longer in general use. A \"large\" or \"stack\", it is usually a reference to a multiple of $1,000 (such as \"fifty large\" meaning $50,000). The $100 note is nicknamed \"Benjamin\", \"Benji\", \"Ben\", or \"Franklin\" (after Benjamin Franklin), \"C-note\" (C being the Roman numeral for 100), \"Century note\" or \"bill\" (e.g. \"two bills\" being $200). The $50 note is occasionally called a \"yardstick\" or a \"grant\" (after President Ulysses S. Grant, pictured on the obverse). The $20 note is referred to as a \"double sawbuck\", \"Jackson\" (after Andrew Jackson), or \"double eagle\". The $10 note is referred to as a \"sawbuck\", \"ten-spot\" or \"Hamilton\" (after Alexander Hamilton). The $5 note as \"Lincoln\", \"fin\", \"fiver\" or \"five-spot\". The infrequently-used $2 note is sometimes called \"deuce\", \"Tom\", or \"Jefferson\" (after Thomas Jefferson). The $1 note as a \"single\" or \"buck\". The dollar has also been, referred to as a \"bone\" and \"bones\" in plural (e.g. \"twenty bones\" is equal to $20). The newer designs, with portraits displayed in the main body of the obverse rather than in cameo insets upon paper color-coded by denomination, are sometimes referred to as \"bigface\" notes or \"Monopoly money\".',\n",
              " 'A \"lock-in\" is when a pub owner lets drinkers stay in the pub after the legal closing time, on the theory that once the doors are locked, it becomes a private party rather than a pub. Patrons may put money behind the bar before official closing time, and redeem their drinks during the lock-in so no drinks are technically sold after closing time. The origin of the British lock-in was a reaction to 1915 changes in the licensing laws in England and Wales, which curtailed opening hours to stop factory workers from turning up drunk and harming the war effort. Since 1915, the UK licensing laws had changed very little, with comparatively early closing times. The tradition of the lock-in therefore remained. Since the implementation of Licensing Act 2003, premises in England and Wales may apply to extend their opening hours beyond 11 pm, allowing round-the-clock drinking and removing much of the need for lock-ins. Since the smoking ban, some establishments operated a lock-in during which the remaining patrons could smoke without repercussions but, unlike drinking lock-ins, allowing smoking in a pub was still a prosecutable offence.',\n",
              " 'A \"tag\" in an audio file is a section of the file that contains metadata such as the title, artist, album, track number or other information about the file\\'s contents. The MP3 standards do not define tag formats for MP3 files, nor is there a standard container format that would support metadata and obviate the need for tags.',\n",
              " 'A 2000 United States Department of the Treasury study of lending trends for 305 cities from 1993 to 1998 showed that $467 billion of mortgage lending was made by Community Reinvestment Act (CRA)-covered lenders into low and mid level income (LMI) borrowers and neighborhoods, representing 10% of all U.S. mortgage lending during the period. The majority of these were prime loans. Sub-prime loans made by CRA-covered institutions constituted a 3% market share of LMI loans in 1998, but in the run-up to the crisis, fully 25% of all sub-prime lending occurred at CRA-covered institutions and another 25% of sub-prime loans had some connection with CRA. In addition, an analysis by the Federal Reserve Bank of Dallas in 2009, however, concluded that the CRA was not responsible for the mortgage loan crisis, pointing out that CRA rules have been in place since 1995 whereas the poor lending emerged only a decade later. Furthermore, most sub-prime loans were not made to the LMI borrowers targeted by the CRA, especially in the years 2005–2006 leading up to the crisis. Nor did it find any evidence that lending under the CRA rules increased delinquency rates or that the CRA indirectly influenced independent mortgage lenders to ramp up sub-prime lending.',\n",
              " 'A 2001 study by Nebel et al. showed that both Ashkenazi and Sephardic Jewish populations share the same overall paternal Near Eastern ancestries. In comparison with data available from other relevant populations in the region, Jews were found to be more closely related to groups in the north of the Fertile Crescent. The authors also report on Eu 19 (R1a) chromosomes, which are very frequent in Central and Eastern Europeans (54%–60%) at elevated frequency (12.7%) in Ashkenazi Jews. They hypothesized that the differences among Ashkenazim Jews could reflect low-level gene flow from surrounding European populations and/or genetic drift during isolation. A later 2005 study by Nebel et al., found a similar level of 11.5% of male Ashkenazim belonging to R1a1a (M17+), the dominant Y-chromosome haplogroup in Central and Eastern Europeans.',\n",
              " 'A 2005 paper states \"recent research has failed to support earlier findings that pet ownership is associated with a reduced risk of cardiovascular disease, a reduced use of general practitioner services, or any psychological or physical benefits on health for community dwelling older people. Research has, however, pointed to significantly less absenteeism from school through sickness among children who live with pets.\" In one study, new guardians reported a highly significant reduction in minor health problems during the first month following pet acquisition, and this effect was sustained in those with dogs through to the end of the study.',\n",
              " 'A 2006 study by Seldin et al. used over five thousand autosomal SNPs to demonstrate European genetic substructure. The results showed \"a consistent and reproducible distinction between \\'northern\\' and \\'southern\\' European population groups\". Most northern, central, and eastern Europeans (Finns, Swedes, English, Irish, Germans, and Ukrainians) showed >90% in the \"northern\" population group, while most individual participants with southern European ancestry (Italians, Greeks, Portuguese, Spaniards) showed >85% in the \"southern\" group. Both Ashkenazi Jews as well as Sephardic Jews showed >85% membership in the \"southern\" group. Referring to the Jews clustering with southern Europeans, the authors state the results were \"consistent with a later Mediterranean origin of these ethnic groups\".',\n",
              " \"A 2006 study found Ashkenazi Jews to be a clear, homogeneous genetic subgroup. Strikingly, regardless of the place of origin, Ashkenazi Jews can be grouped in the same genetic cohort – that is, regardless of whether an Ashkenazi Jew's ancestors came from Poland, Russia, Hungary, Lithuania, or any other place with a historical Jewish population, they belong to the same ethnic group. The research demonstrates the endogamy of the Jewish population in Europe and lends further credence to the idea of Ashkenazi Jews as an ethnic group. Moreover, though intermarriage among Jews of Ashkenazi descent has become increasingly common, many Haredi Jews, particularly members of Hasidic or Hareidi sects, continue to marry exclusively fellow Ashkenazi Jews. This trend keeps Ashkenazi genes prevalent and also helps researchers further study the genes of Ashkenazi Jews with relative ease. It is noteworthy that these Haredi Jews often have extremely large families.\",\n",
              " 'A 2007 study conducted by the National Science Foundation found that biodiversity and genetic diversity are codependent—that diversity among species requires diversity within a species, and vice versa. \"If any one type is removed from the system, the cycle can break down, and the community becomes dominated by a single species.\" At present, the most threatened ecosystems are found in fresh water, according to the Millennium Ecosystem Assessment 2005, which was confirmed by the \"Freshwater Animal Diversity Assessment\", organised by the biodiversity platform, and the French Institut de recherche pour le développement (MNHNP).',\n",
              " 'A 2009 Cochrane review concluded that thiazide antihypertensive drugs reduce the risk of death (RR 0.89), stroke (RR 0.63), coronary heart disease (RR 0.84), and cardiovascular events (RR 0.70) in people with high blood pressure. In the ensuring years other classes of antihypertensive drug were developed and found wide acceptance in combination therapy, including loop diuretics (Lasix/furosemide, Hoechst Pharmaceuticals, 1963), beta blockers (ICI Pharmaceuticals, 1964) ACE inhibitors, and angiotensin receptor blockers. ACE inhibitors reduce the risk of new onset kidney disease [RR 0.71] and death [RR 0.84] in diabetic patients, irrespective of whether they have hypertension.',\n",
              " 'A 2010 study by Bray et al., using SNP microarray techniques and linkage analysis found that when assuming Druze and Palestinian Arab populations to represent the reference to world Jewry ancestor genome, between 35 to 55 percent of the modern Ashkenazi genome can possibly be of European origin, and that European \"admixture is considerably higher than previous estimates by studies that used the Y chromosome\" with this reference point. Assuming this reference point the linkage disequilibrium in the Ashkenazi Jewish population was interpreted as \"matches signs of interbreeding or \\'admixture\\' between Middle Eastern and European populations\". On the Bray et al. tree, Ashkenazi Jews were found to be a genetically more divergent population than Russians, Orcadians, French, Basques, Italians, Sardinians and Tuscans. The study also observed that Ashkenazim are more diverse than their Middle Eastern relatives, which was counterintuitive because Ashkenazim are supposed to be a subset, not a superset, of their assumed geographical source population. Bray et al. therefore postulate that these results reflect not the population antiquity but a history of mixing between genetically distinct populations in Europe. However, it\\'s possible that the relaxation of marriage prescription in the ancestors of Ashkenazim that drove their heterozygosity up, while the maintenance of the FBD rule in native Middle Easterners have been keeping their heterozygosity values in check. Ashkenazim distinctiveness as found in the Bray et al. study, therefore, may come from their ethnic endogamy (ethnic inbreeding), which allowed them to \"mine\" their ancestral gene pool in the context of relative reproductive isolation from European neighbors, and not from clan endogamy (clan inbreeding). Consequently, their higher diversity compared to Middle Easterners stems from the latter\\'s marriage practices, not necessarily from the former\\'s admixture with Europeans.',\n",
              " 'A 2010 study on Jewish ancestry by Atzmon-Ostrer et al. stated \"Two major groups were identified by principal component, phylogenetic, and identity by descent (IBD) analysis: Middle Eastern Jews and European/Syrian Jews. The IBD segment sharing and the proximity of European Jews to each other and to southern European populations suggested similar origins for European Jewry and refuted large-scale genetic contributions of Central and Eastern European and Slavic populations to the formation of Ashkenazi Jewry\", as both groups – the Middle Eastern Jews and European/Syrian Jews – shared common ancestors in the Middle East about 2500 years ago. The study examines genetic markers spread across the entire genome and shows that the Jewish groups (Ashkenazi and non Ashkenazi) share large swaths of DNA, indicating close relationships and that each of the Jewish groups in the study (Iranian, Iraqi, Syrian, Italian, Turkish, Greek and Ashkenazi) has its own genetic signature but is more closely related to the other Jewish groups than to their fellow non-Jewish countrymen. Atzmon\\'s team found that the SNP markers in genetic segments of 3 million DNA letters or longer were 10 times more likely to be identical among Jews than non-Jews. Results of the analysis also tally with biblical accounts of the fate of the Jews. The study also found that with respect to non-Jewish European groups, the population most closely related to Ashkenazi Jews are modern-day Italians. The study speculated that the genetic-similarity between Ashkenazi Jews and Italians may be due to inter-marriage and conversions in the time of the Roman Empire. It was also found that any two Ashkenazi Jewish participants in the study shared about as much DNA as fourth or fifth cousins.',\n",
              " 'A 2011 discovery in the Canadian province of New Brunswick uncovered the earliest known plants to have grown wood, approximately 395 to 400 million years ago. Wood can be dated by carbon dating and in some species by dendrochronology to make inferences about when a wooden object was created.',\n",
              " 'A 2011 study by the Translational Genomics Research Institute showed that 47% of the meat and poultry sold in United States grocery stores was contaminated with Staphylococcus aureus, and 52% of the bacteria concerned showed resistance to at least three groups of antibiotics. Thorough cooking of the product would kill these bacteria, but a risk of cross-contamination from improper handling of the raw product is still present. Also, some risk is present for consumers of poultry meat and eggs to bacterial infections such as Salmonella and Campylobacter. Poultry products may become contaminated by these bacteria during handling, processing, marketing, or storage, resulting in food-borne illness if the product is improperly cooked or handled.',\n",
              " 'A 2013 study in Nature reported that DNA found in the 24,000-year-old remains of a young boy from the archaeological Mal\\'ta-Buret\\' culture suggest that up to one-third of the indigenous Americans may have ancestry that can be traced back to western Eurasians, who may have \"had a more north-easterly distribution 24,000 years ago than commonly thought\". \"We estimate that 14 to 38 percent of Native American ancestry may originate through gene flow from this ancient population,\" the authors wrote. Professor Kelly Graf said,',\n",
              " 'A 2013 trans-genome study carried out by 30 geneticists, from 13 universities and academies, from 9 countries, assembling the largest data set available to date, for assessment of Ashkenazi Jewish genetic origins found no evidence of Khazar origin among Ashkenazi Jews. \"Thus, analysis of Ashkenazi Jews together with a large sample from the region of the Khazar Khaganate corroborates the earlier results that Ashkenazi Jews derive their ancestry primarily from populations of the Middle East and Europe, that they possess considerable shared ancestry with other Jewish populations, and that there is no indication of a significant genetic contribution either from within or from north of the Caucasus region\", the authors concluded.',\n",
              " 'A 2014 profile by the National Health Service showed Plymouth had higher than average levels of poverty and deprivation (26.2% of population among the poorest 20.4% nationally). Life expectancy, at 78.3 years for men and 82.1 for women, was the lowest of any region in the South West of England.',\n",
              " \"A 5th-century building in Huldah may be a Samaritan synagogue. Its mosaic floor contains typical Jewish symbols (menorah, lulav, etrog) but the inscriptions are Greek. Another Samaritan synagogue with a mosaic floor was located in Bet She'an (excavated in 1960). The floor had only decorative motifs and an aedicule (shrine) with cultic symbols. The ban on human or animal images was more strictly observed by the Samaritans than their Jewish neighbours in the same town (see above). The mosaic was laid by the same masters who made the floor of the Beit Alfa synagogue. One of the inscriptions was written in Samaritan script.\",\n",
              " 'A CD containing 20 musical selections from the game was available as a GameStop preorder bonus in the United States; it is included in all bundles in Japan, Europe, and Australia.[citation needed]',\n",
              " 'A CD is read by focusing a 780 nm wavelength (near infrared) semiconductor laser housed within the CD player, through the bottom of the polycarbonate layer. The change in height between pits and lands results in a difference in the way the light is reflected. By measuring the intensity change with a photodiode, the data can be read from the disc. In order to accommodate the spiral pattern of data, the semiconductor laser is placed on a swing arm within the disc tray of any CD player. This swing arm allows the laser to read information from the centre to the edge of a disc, without having to interrupt the spinning of the disc itself.',\n",
              " 'A Christian ( pronunciation (help·info)) is a person who adheres to Christianity, an Abrahamic, monotheistic religion based on the life and teachings of Jesus Christ. \"Christian\" derives from the Koine Greek word Christós (Χριστός), a translation of the Biblical Hebrew term mashiach.',\n",
              " 'A Colorado study found bites in children were less severe than bites in adults. The incidence of dog bites in the US is 12.9 per 10,000 inhabitants, but for boys aged 5 to 9, the incidence rate is 60.7 per 10,000. Moreover, children have a much higher chance to be bitten in the face or neck. Sharp claws with powerful muscles behind them can lacerate flesh in a scratch that can lead to serious infections.',\n",
              " \"A DBMS has evolved into a complex software system and its development typically requires thousands of human years of development effort.[a] Some general-purpose DBMSs such as Adabas, Oracle and DB2 have been undergoing upgrades since the 1970s. General-purpose DBMSs aim to meet the needs of as many applications as possible, which adds to the complexity. However, the fact that their development cost can be spread over a large number of users means that they are often the most cost-effective approach. However, a general-purpose DBMS is not always the optimal solution: in some cases a general-purpose DBMS may introduce unnecessary overhead. Therefore, there are many examples of systems that use special-purpose databases. A common example is an email system that performs many of the functions of a general-purpose DBMS such as the insertion and deletion of messages composed of various items of data or associating messages with a particular email address; but these functions are limited to what is required to handle email and don't provide the user with all of the functionality that would be available using a general-purpose DBMS.\",\n",
              " 'A Federal Trade Commission report issued in 1958 attempted to quantify the effect of antibiotic development on American public health. The report found that over the period 1946-1955, there was a 42% drop in the incidence of diseases for which antibiotics were effective and only a 20% drop in those for which antibiotics were not effective. The report concluded that \"it appears that the use of antibiotics, early diagnosis, and other factors have limited the epidemic spread and thus the number of these diseases which have occurred\". The study further examined mortality rates for eight common diseases for which antibiotics offered effective therapy (syphilis, tuberculosis, dysentery, scarlet fever, whooping cough, meningococcal infections, and pneumonia), and found a 56% decline over the same period. Notable among these was a 75% decline in deaths due to tuberculosis.',\n",
              " 'A Frankish identity emerged and so did their Frankish or Franconian language. The language itself is poorly attested. A notable exception is the Bergakker inscription, found near the Dutch city of Tiel, which may represent a primary record of 5th-century Frankish. Although some placenames recorded in Roman texts could arguably be considered as the oldest \"Dutch\" single words, like vadam (modern Dutch: wad, English: \"mudflat\"), the Bergakker inscription yields the oldest evidence of Dutch morphology, but there is no consensus on the interpretation of the rest of the text.',\n",
              " \"A Freedom of Information request in 2005 revealed that Eton had received £2,652 in farming subsidies in 2004 under the Common Agricultural Policy. Asked to explain under what grounds it was eligible to receive farming subsidies, Eton admitted that it was 'a bit of a mystery'. The TaxPayers' Alliance also stated that Eton had received a total of £5,300 in CAP subsidies between 2002 and 2007. Panorama revealed in March 2012 that farming subsidies were granted to Eton for 'environmental improvements', in effect 'being paid without having to do any farming at all'.\",\n",
              " 'A German ethnicity emerged in the course of the Middle Ages, ultimately as a result of the formation of the kingdom of Germany within East Francia and later the Holy Roman Empire, beginning in the 9th century. The process was gradual and lacked any clear definition, and the use of exonyms designating \"the Germans\" develops only during the High Middle Ages. The title of rex teutonicum \"King of the Germans\" is first used in the late 11th century, by the chancery of Pope Gregory VII, to describe the future Holy Roman Emperor of the German Nation Henry IV. Natively, the term ein diutscher (\"a German\") is used for the people of Germany from the 12th century.',\n",
              " 'A German trading company, the Jaluit Gesellschaft, administered the islands from 1887 until 1905. They conscripted the islanders as laborers and mistreated them. After the German–Spanish Treaty of 1899, in which Germany acquired the Carolines, Palau, and the Marianas from Spain, Germany placed all of its Micronesian islands, including the Marshalls, under the governor of German New Guinea.',\n",
              " 'A HDI below 0.5 is considered to represent \"low development\". All 22 countries in that category are located in Africa. The highest-scoring Sub-Saharan countries, Gabon and South Africa, are ranked 119th and 121st, respectively. Nine countries departed from this category this year and joined the \"medium development\" group.',\n",
              " 'A HDI of 0.8 or more is considered to represent \"high development\". This includes all developed countries, such as those in North America, Western Europe, Oceania, and Eastern Asia, as well as some developing countries in Eastern Europe, Central and South America, Southeast Asia, the Caribbean, and the oil-rich Arabian Peninsula. Seven countries were promoted to this category this year, leaving the \"medium development\" group: Albania, Belarus, Brazil, Libya, Macedonia, Russia and Saudi Arabia.',\n",
              " 'A January 2013 press release from the USB group revealed plans to update USB 3.0 to 10 Gbit/s. The group ended up creating a new USB version, USB 3.1, which was released on 31 July 2013, introducing a faster transfer mode called SuperSpeed USB 10 Gbit/s, putting it on par with a single first-generation Thunderbolt channel. The new mode\\'s logo features a \"Superspeed+\" caption (stylized as SUPERSPEED+). The USB 3.1 standard increases the data signaling rate to 10 Gbit/s in the USB 3.1 Gen2 mode, double that of USB 3.0 (referred to as USB 3.1 Gen1) and reduces line encoding overhead to just 3% by changing the encoding scheme to 128b/132b. The first USB 3.1 implementation demonstrated transfer speeds of 7.2 Gbit/s.',\n",
              " \"A Japan-exclusive manga series based on Twilight Princess, penned and illustrated by Akira Himekawa, was first released on February 8, 2016. The series is available solely via publisher Shogakukan's MangaOne mobile application. While the manga adaptation began almost ten years after the initial release of the game on which it is based, it launched only a month before the release of the high-definition remake.\",\n",
              " \"A Japanese force was sent north to attack the Aleutian Islands. The next stage of the plan called for the capture of Midway, which would give him an opportunity to destroy Nimitz's remaining carriers. In May, Allied codebreakers discovered his intentions. Nagumo was again in tactical command but was focused on the invasion of Midway; Yamamoto's complex plan had no provision for intervention by Nimitz before the Japanese expected him. Planned surveillance of the U.S. fleet by long range seaplane did not happen (as a result of an abortive identical operation in March), so Fletcher's carriers were able to proceed to a flanking position without being detected. Nagumo had 272 planes operating from his four carriers, the U.S. 348 (115 land-based).\",\n",
              " \"A Latin translation of Ibn Tufail's work, Philosophus Autodidactus, first appeared in 1671, prepared by Edward Pococke the Younger, followed by an English translation by Simon Ockley in 1708, as well as German and Dutch translations. These translations might have later inspired Daniel Defoe to write Robinson Crusoe, regarded as the first novel in English. Philosophus Autodidactus, continuing the thoughts of philosophers such as Aristotle from earlier ages, inspired Robert Boyle to write his own philosophical novel set on an island, The Aspiring Naturalist.\",\n",
              " 'A Macau resident was arrested on April 26 for posting a message on cyberctm.com encouraging people to disrupt the relay. Both orchidbbs.com and cyberctm.com Internet forums were shut down from May 2 to 4. This fueled speculation that the shutdowns were targeting speeches against the relay. The head of the Bureau of Telecommunications Regulation has denied that the shutdowns of the websites were politically motivated. About 2,200 police were deployed on the streets, there were no interruptions.',\n",
              " 'A Misratan militia took Gaddafi prisoner, beating him, causing serious injuries; the events were filmed on a mobile phone. A video appears to picture Gaddafi being poked or stabbed in the rear end \"with some kind of stick or knife\" or possibly a bayonet. Pulled onto the front of a pick-up truck, he fell off as it drove away. His semi-naked, lifeless body was then placed into an ambulance and taken to Misrata; upon arrival, he was found to be dead. Official NTC accounts claimed that Gaddafi was caught in a cross-fire and died from his bullet wounds. Other eye-witness accounts claimed that rebels had fatally shot Gaddafi in the stomach; a rebel identifying himself as Senad el-Sadik el-Ureybi later claimed responsibility. Gaddafi\\'s son Mutassim, who had also been among the convoy, was also captured, and found dead several hours later, most probably from an extrajudicial execution. Around 140 Gaddafi loyalists were rounded up from the convoy; tied up and abused, the corpses of 66 were found at the nearby Mahari Hotel, victims of extrajudicial execution. Libya\\'s chief forensic pathologist, Dr. Othman al-Zintani, carried out the autopsies of Gaddafi, his son and Jabr in the days following their deaths; although the pathologist initially told the press that Gaddafi had died from a gunshot wound to the head, the autopsy report was not made public.',\n",
              " 'A P-N junction can convert absorbed light energy into a proportional electric current. The same process is reversed here (i.e. the P-N junction emits light when electrical energy is applied to it). This phenomenon is generally called electroluminescence, which can be defined as the emission of light from a semi-conductor under the influence of an electric field. The charge carriers recombine in a forward-biased P-N junction as the electrons cross from the N-region and recombine with the holes existing in the P-region. Free electrons are in the conduction band of energy levels, while holes are in the valence energy band. Thus the energy level of the holes will be lesser than the energy levels of the electrons. Some portion of the energy must be dissipated in order to recombine the electrons and the holes. This energy is emitted in the form of heat and light.',\n",
              " 'A PM motor does not have a field winding on the stator frame, instead relying on PMs to provide the magnetic field against which the rotor field interacts to produce torque. Compensating windings in series with the armature may be used on large motors to improve commutation under load. Because this field is fixed, it cannot be adjusted for speed control. PM fields (stators) are convenient in miniature motors to eliminate the power consumption of the field winding. Most larger DC motors are of the \"dynamo\" type, which have stator windings. Historically, PMs could not be made to retain high flux if they were disassembled; field windings were more practical to obtain the needed amount of flux. However, large PMs are costly, as well as dangerous and difficult to assemble; this favors wound fields for large machines.',\n",
              " 'A Protestant baptism is held to be valid by the Catholic Church if given with the trinitarian formula and with the intent to baptize. However, as the ordination of Protestant ministers is not recognized due to the lack of apostolic succession and the disunity from Catholic Church, all other sacraments (except marriage) performed by Protestant denominations and ministers are not recognized as valid. Therefore, Protestants desiring full communion with the Catholic Church are not re-baptized (although they are confirmed) and Protestant ministers who become Catholics may be ordained to the priesthood after a period of study.',\n",
              " 'A Royal Charter in 1952 upgraded University College at Highfield to the University of Southampton. Southampton acquired city status, becoming the City of Southampton in 1964.',\n",
              " 'A Science Hall was built in 1883 under the direction of Fr. Zahm, but in 1950 it was converted to a student union building and named LaFortune Center, after Joseph LaFortune, an oil executive from Tulsa, Oklahoma. Commonly known as \"LaFortune\" or \"LaFun,\" it is a 4-story building of 83,000 square feet that provides the Notre Dame community with a meeting place for social, recreational, cultural, and educational activities. LaFortune employs 35 part-time student staff and 29 full-time non-student staff and has an annual budget of $1.2 million. Many businesses, services, and divisions of The Office of Student Affairs are found within. The building also houses restaurants from national restaurant chains.',\n",
              " 'A Spanish expedition led by captain Estêvão Gomes, a Portuguese sailing for Emperor Charles V, arrived in New York Harbor in January 1525 aboard the purpose-built caravel \"La Anunciada\" and charted the mouth of the Hudson River, which he named Rio de San Antonio. Heavy ice kept him from further exploration, and he returned to Spain in August. The first scientific map to show the North American East coast continuously, the 1527 world map known as the Padrón Real, was informed by Gomes\\' expedition, and labeled the Northeast as Tierra de Esteban Gómez in his honor.',\n",
              " 'A Spanish expedition was sent from Buenos Aires, organized by the Spanish governor of that city, Bruno Mauricio de Zabala. On 22 January 1724, the Spanish forced the Portuguese to abandon the location and started populating the city, initially with six families moving in from Buenos Aires and soon thereafter by families arriving from the Canary Islands who were called by the locals \"guanches\", \"guanchos\" or \"canarios\". There was also one significant early Italian resident by the name of Jorge Burgues.',\n",
              " 'A TiVo service update in July 2008 allowed the system to search and play YouTube videos. In January 2009, YouTube launched \"YouTube for TV\", a version of the website tailored for set-top boxes and other TV-based media devices with web browsers, initially allowing its videos to be viewed on the PlayStation 3 and Wii video game consoles. In June 2009, YouTube XL was introduced, which has a simplified interface designed for viewing on a standard television screen. YouTube is also available as an app on Xbox Live. On November 15, 2012, Google launched an official app for the Wii, allowing users to watch YouTube videos from the Wii channel. An app is also available for Wii U and Nintendo 3DS, and videos can be viewed on the Wii U Internet Browser using HTML5. Google made YouTube available on the Roku player on December 17, 2013 and in October 2014, the Sony PlayStation 4.',\n",
              " 'A Turco-Mongol conqueror in Central Asia, Timur (Tamerlane), attacked the reigning Sultan Nasir-u Din Mehmud of the Tughlaq Dynasty in the north Indian city of Delhi. The Sultan\\'s army was defeated on 17 December 1398. Timur entered Delhi and the city was sacked, destroyed, and left in ruins, after Timur\\'s army had killed and plundered for three days and nights. He ordered the whole city to be sacked except for the sayyids, scholars, and the \"other Muslims\" (artists); 100,000 war prisoners were put to death in one day. The Sultanate suffered significantly from the sacking of Delhi revived briefly under the Lodi Dynasty, but it was a shadow of the former.',\n",
              " 'A UCLA research study published in the June 2006 issue of the American Journal of Geriatric Psychiatry found that people can improve cognitive function and brain efficiency through simple lifestyle changes such as incorporating memory exercises, healthy eating, physical fitness and stress reduction into their daily lives. This study examined 17 subjects, (average age 53) with normal memory performance. Eight subjects were asked to follow a \"brain healthy\" diet, relaxation, physical, and mental exercise (brain teasers and verbal memory training techniques). After 14 days, they showed greater word fluency (not memory) compared to their baseline performance. No long term follow up was conducted, it is therefore unclear if this intervention has lasting effects on memory.',\n",
              " 'A USB packet\\'s end, called EOP (end-of-packet), is indicated by the transmitter driving 2 bit times of SE0 (D+ and D− both below max.) and 1 bit time of J state. After this, the transmitter ceases to drive the D+/D− lines and the aforementioned pull up resistors hold it in the J (idle) state. Sometimes skew due to hubs can add as much as one bit time before the SE0 of the end of packet. This extra bit can also result in a \"bit stuff violation\" if the six bits before it in the CRC are 1s. This bit should be ignored by receiver.',\n",
              " \"A Vestal's dress represented her status outside the usual categories that defined Roman women, with elements of both virgin bride and daughter, and Roman matron and wife. Unlike male priests, Vestals were freed of the traditional obligations of marrying and producing children, and were required to take a vow of chastity that was strictly enforced: a Vestal polluted by the loss of her chastity while in office was buried alive. Thus the exceptional honor accorded a Vestal was religious rather than personal or social; her privileges required her to be fully devoted to the performance of her duties, which were considered essential to the security of Rome.\",\n",
              " \"A Yagi-Uda array uses passive elements to greatly increase gain. It is built along a support boom that is pointed toward the signal, and thus sees no induced signal and does not contribute to the antenna's operation. The end closer to the source is referred to as the front. Near the rear is a single active element, typically a half-wave dipole or folded dipole. Passive elements are arranged in front (directors) and behind (reflectors) the active element along the boom. The Yagi has the inherent quality that it becomes increasingly directional, and thus has higher gain, as the number of elements increases. However, this also makes it increasingly sensitive to changes in frequency; if the signal frequency changes, not only does the active element receive less energy directly, but all of the passive elements adding to that signal also decrease their output as well and their signals no longer reach the active element in-phase.\",\n",
              " \"A ballot initiative in Colorado, known as Amendment 36, would have changed the way in which the state apportions its electoral votes. Rather than assigning all 9 of the state's electors to the candidate with a plurality of popular votes, under the amendment Colorado would have assigned presidential electors proportionally to the statewide vote count, which would be a unique system (Nebraska and Maine assign electoral votes based on vote totals within each congressional district). Detractors claimed that this splitting would diminish Colorado's influence in the Electoral College, and the amendment ultimately failed, receiving only 34% of the vote.\",\n",
              " 'A band of Middle Devonian limestone runs west to east from Cremyll to Plymstock including the Hoe. Local limestone may be seen in numerous buildings, walls and pavements throughout Plymouth. To the north and north east of the city is the granite mass of Dartmoor; the granite was mined and exported via Plymouth. Rocks brought down the Tamar from Dartmoor include ores containing tin, copper, tungsten, lead and other minerals. There is evidence that the middle Devonian limestone belt at the south edge of Plymouth and in Plymstock was quarried at West Hoe, Cattedown and Radford.',\n",
              " 'A bantam is a small variety of domestic chicken, either a miniature version of a member of a standard breed, or a \"true bantam\" with no larger counterpart. The name derives from the town of Bantam in Java where European sailors bought the local small chickens for their shipboard supplies. Bantams may be a quarter to a third of the size of standard birds and lay similarly small eggs. They are kept by small-holders and hobbyists for egg production, use as broody hens, ornamental purposes, and showing.',\n",
              " 'A bare proton, H+, cannot exist in solution or in ionic crystals, because of its unstoppable attraction to other atoms or molecules with electrons. Except at the high temperatures associated with plasmas, such protons cannot be removed from the electron clouds of atoms and molecules, and will remain attached to them. However, the term \\'proton\\' is sometimes used loosely and metaphorically to refer to positively charged or cationic hydrogen attached to other species in this fashion, and as such is denoted \"H+\" without any implication that any single protons exist freely as a species.',\n",
              " 'A belt of massive fortifications was established around the city, most of which still stands today, renamed after French generals and generally classified as Monuments historiques; most notably Fort Roon (now Fort Desaix) and Fort Podbielski (now Fort Ducrot) in Mundolsheim, Fort von Moltke (now Fort Rapp) in Reichstett, Fort Bismarck (now Fort Kléber) in Wolfisheim, Fort Kronprinz (now Fort Foch) in Niederhausbergen, Fort Kronprinz von Sachsen (now Fort Joffre) in Holtzheim and Fort Großherzog von Baden (now Fort Frère) in Oberhausbergen.',\n",
              " 'A boy who is late for any division or other appointment may be required to sign \"Tardy Book\", a register kept in the School Office, between 7.35am and 7.45am, every morning for the duration of his sentence (typically three days). Tardy Book may also be issued for late work. For more serious misdeeds, a boy is summoned from his lessons to the Head Master, or Lower Master if the boy is in the lower two years, to talk personally about his misdeeds. This is known as the \"Bill\". The most serious misdeeds may result in expulsion, or rustication (suspension). Conversely, should a master be more than 15 minutes late for a class, traditionally the pupils might claim it as a \"run\" and absent themselves for the rest of its duration.',\n",
              " 'A brash boosterism that had typified Melbourne during this time ended in the early 1890s with a severe depression of the city\\'s economy, sending the local finance and property industries into a period of chaos during which 16 small \"land banks\" and building societies collapsed, and 133 limited companies went into liquidation. The Melbourne financial crisis was a contributing factor in the Australian economic depression of the 1890s and the Australian banking crisis of 1893. The effects of the depression on the city were profound, with virtually no new construction until the late 1890s.',\n",
              " \"A brewery tap is the nearest outlet for a brewery's beers. This is usually a room or bar in the brewery itself, though the name may be applied to the nearest pub. The term is not applied to a brewpub which brews and sells its beer on the same premises.\",\n",
              " \"A brief shoot at London's City Hall was filmed on 18 April 2015, while Mendes was on location. On 17 May 2015 filming took place on the Thames in London. Stunt scenes involving Craig and Seydoux on a speedboat as well as a low flying helicopter near Westminster Bridge were shot at night, with filming temporarily closing both Westminster and Lambeth Bridges. Scenes were also shot on the river near MI6's headquarters at Vauxhall Cross. The crew returned to the river less than a week later to film scenes solely set on Westminster Bridge. The London Fire Brigade was on set to simulate rain as well as monitor smoke used for filming. Craig, Seydoux, and Waltz, as well as Harris and Fiennes, were seen being filmed. Prior to this, scenes involving Fiennes were shot at a restaurant in Covent Garden. Filming then took place in Trafalgar Square. In early June, the crew, as well as Craig, Seydoux, and Waltz, returned to the Thames for a final time to continue filming scenes previously shot on the river.\",\n",
              " 'A broad operational definition is sometimes used to encompass the complexity of these diverse phenomena, where a gene is defined as a union of genomic sequences encoding a coherent set of potentially overlapping functional products. This definition categorizes genes by their functional products (proteins or RNA) rather than their specific DNA loci, with regulatory elements classified as gene-associated regions.',\n",
              " 'A broad way of defining adolescence is the transition from child-to-adulthood. According to Hogan & Astone (1986), this transition can include markers such as leaving school, starting a full-time job, leaving the home of origin, getting married, and becoming a parent for the first time. However, the time frame of this transition varies drastically by culture. In some countries, such as the United States, adolescence can last nearly a decade, but in others, the transition—often in the form of a ceremony—can last for only a few days.',\n",
              " 'A browser extension is a computer program that extends the functionality of a web browser. Every major web browser supports the development of browser extensions.',\n",
              " 'A cabinet of coins is the Münzkabinett der TUI-AG. The Polizeigeschichtliche Sammlung Niedersachsen is the largest police museum in Germany. Textiles from all over the world can be visited in the Museum for textile art. The EXPOseeum is the museum of the world-exhibition \"EXPO 2000 Hannover\". Carpets and objects from the orient can be visited in the Oriental Carpet Museum. The Blind Man Museum is a rarity in Germany, another one is only in Berlin. The Museum of veterinary medicine is unique in Germany. The Museum for Energy History describes the 150 years old history of the application of energy. The Home Museum Ahlem shows the history of the district of Ahlem. The Mahn- und Gedenkstätte Ahlem describes the history of the Jewish people in Hanover and the Stiftung Ahlers Pro Arte / Kestner Pro Arte shows modern art. Modern art is also the main topic of the Kunsthalle Faust, the Nord/LB Art Gellery and of the Foro Artistico / Eisfabrik.',\n",
              " \"A capacitor (originally known as a condenser) is a passive two-terminal electrical component used to store electrical energy temporarily in an electric field. The forms of practical capacitors vary widely, but all contain at least two electrical conductors (plates) separated by a dielectric (i.e. an insulator that can store energy by becoming polarized). The conductors can be thin films, foils or sintered beads of metal or conductive electrolyte, etc. The nonconducting dielectric acts to increase the capacitor's charge capacity. Materials commonly used as dielectrics include glass, ceramic, plastic film, air, vacuum, paper, mica, and oxide layers. Capacitors are widely used as parts of electrical circuits in many common electrical devices. Unlike a resistor, an ideal capacitor does not dissipate energy. Instead, a capacitor stores energy in the form of an electrostatic field between its plates.\",\n",
              " 'A capacitor consists of two conductors separated by a non-conductive region. The non-conductive region is called the dielectric. In simpler terms, the dielectric is just an electrical insulator. Examples of dielectric media are glass, air, paper, vacuum, and even a semiconductor depletion region chemically identical to the conductors. A capacitor is assumed to be self-contained and isolated, with no net electric charge and no influence from any external electric field. The conductors thus hold equal and opposite charges on their facing surfaces, and the dielectric develops an electric field. In SI units, a capacitance of one farad means that one coulomb of charge on each conductor causes a voltage of one volt across the device.',\n",
              " 'A cappella [a kapˈpɛlla] (Italian for \"in the manner of the chapel\") music is specifically group or solo singing without instrumental accompaniment, or a piece intended to be performed in this way. It contrasts with cantata, which is accompanied singing. The term \"a cappella\" was originally intended to differentiate between Renaissance polyphony and Baroque concertato style. In the 19th century a renewed interest in Renaissance polyphony coupled with an ignorance of the fact that vocal parts were often doubled by instrumentalists led to the term coming to mean unaccompanied vocal music. The term is also used, albeit rarely, as a synonym for alla breve.',\n",
              " \"A cappella has been used as the sole orchestration for original works of musical theater that have had commercial runs Off-Broadway (theaters in New York City with 99 to 500 seats) only four times. The first was Avenue X which opened on 28 January 1994 and ran for 77 performances. It was produced by Playwrights Horizons with book by John Jiler, music and lyrics by Ray Leslee. The musical style of the show's score was primarily Doo-Wop as the plot revolved around Doo-Wop group singers of the 1960s.\",\n",
              " 'A cappella is gaining popularity among South Asians with the emergence of primarily Hindi-English College groups. The first South Asian a cappella group was Penn Masala, founded in 1996 at the University of Pennsylvania. Co-ed South Asian a cappella groups are also gaining in popularity. The first co-ed south Asian a cappella was Anokha, from the University of Maryland, formed in 2001. Also, Dil se, another co-ed a cappella from UC Berkeley, hosts the \"Anahat\" competition at the University of California, Berkeley annually. Maize Mirchi, the co-ed a cappella group from the University of Michigan hosts \"Sa Re Ga Ma Pella\", an annual South Asian a cappella invitational with various groups from the Midwest.',\n",
              " 'A cappella music was originally used in religious music, especially church music as well as anasheed and zemirot. Gregorian chant is an example of a cappella singing, as is the majority of secular vocal music from the Renaissance. The madrigal, up until its development in the early Baroque into an instrumentally-accompanied form, is also usually in a cappella form. Jewish and Christian music were originally a cappella,[citation needed] and this practice has continued in both of these religions as well as in Islam.',\n",
              " \"A cardinal (Latin: sanctae romanae ecclesiae cardinalis, literally cardinal of the Holy Roman Church) is a senior ecclesiastical leader, an ecclesiastical prince, and usually (now always for those created when still within the voting age-range) an ordained bishop of the Roman Catholic Church. The cardinals of the Church are collectively known as the College of Cardinals. The duties of the cardinals include attending the meetings of the College and making themselves available individually or in groups to the Pope as requested. Most have additional duties, such as leading a diocese or archdiocese or managing a department of the Roman Curia. A cardinal's primary duty is electing the pope when the see becomes vacant. During the sede vacante (the period between a pope's death or resignation and the election of his successor), the day-to-day governance of the Holy See is in the hands of the College of Cardinals. The right to enter the conclave of cardinals where the pope is elected is limited to those who have not reached the age of 80 years by the day the vacancy occurs.\",\n",
              " 'A cardinal who is not a bishop is still entitled to wear and use the episcopal vestments and other pontificalia (episcopal regalia: mitre, crozier, zucchetto, pectoral cross and ring). Even if not a bishop, any cardinal has both actual and honorary precedence over non-cardinal patriarchs, as well as the archbishops and bishops who are not cardinals, but he cannot perform the functions reserved solely to bishops, such as ordination. The prominent priests who since 1962 were not ordained bishops on their elevation to the cardinalate were over the age of 80 or near to it, and so no cardinal who was not a bishop has participated in recent papal conclaves.',\n",
              " 'A census of sea life carried out during the International Polar Year and which involved some 500 researchers was released in 2010. The research is part of the global Census of Marine Life (CoML) and has disclosed some remarkable findings. More than 235 marine organisms live in both polar regions, having bridged the gap of 12,000 km (7,456 mi). Large animals such as some cetaceans and birds make the round trip annually. More surprising are small forms of life such as mudworms, sea cucumbers and free-swimming snails found in both polar oceans. Various factors may aid in their distribution – fairly uniform temperatures of the deep ocean at the poles and the equator which differ by no more than 5 °C, and the major current systems or marine conveyor belt which transport eggs and larval stages.',\n",
              " 'A central teaching of Jehovah\\'s Witnesses is that the current world era, or \"system of things\", entered the \"last days\" in 1914 and faces imminent destruction through intervention by God and Jesus Christ, leading to deliverance for those who worship God acceptably. They consider all other present-day religions to be false, identifying them with \"Babylon the Great\", or the \"harlot\", of Revelation 17, and believe that they will soon be destroyed by the United Nations, which they believe is represented in scripture by the scarlet-colored wild beast of Revelation chapter 17. This development will mark the beginning of the \"great tribulation\". Satan will subsequently attack Jehovah\\'s Witnesses, an action that will prompt God to begin the war of Armageddon, during which all forms of government and all people not counted as Christ\\'s \"sheep\", or true followers, will be destroyed. After Armageddon, God will extend his heavenly kingdom to include earth, which will be transformed into a paradise similar to the Garden of Eden. After Armageddon, most of those who had died before God\\'s intervention will gradually be resurrected during \"judgment day\" lasting for one thousand years. This judgment will be based on their actions after resurrection rather than past deeds. At the end of the thousand years, Christ will hand all authority back to God. Then a final test will take place when Satan is released to mislead perfect mankind. Those who fail will be destroyed, along with Satan and his demons. The end result will be a fully tested, glorified human race.',\n",
              " 'A charity is a nonprofit organisation that meets stricter criteria regarding its purpose and the method in which it makes decisions and reports its finances. For example, a charity is generally not allowed to pay its Trustees. In England and Wales, charities may be registered with the Charity Commission. In Scotland, the Office of the Scottish Charity Regulator serves the same function. Other organizations which are classified as nonprofit organizations elsewhere, such as trade unions, are subject to separate regulations, and are not regarded as \"charities\" in the technical sense.',\n",
              " 'A climbing elevator is a self-ascending elevator with its own propulsion. The propulsion can be done by an electric or a combustion engine. Climbing elevators are used in guyed masts or towers, in order to make easy access to parts of these constructions, such as flight safety lamps for maintenance. An example would be the Moonlight towers in Austin, Texas, where the elevator holds only one person and equipment for maintenance. The Glasgow Tower — an observation tower in Glasgow, Scotland — also makes use of two climbing elevators.',\n",
              " \"A collector of film memorabilia, Spielberg purchased a balsa Rosebud sled from Citizen Kane (1941) in 1982. He bought Orson Welles's own directorial copy of the script for the radio broadcast The War of the Worlds (1938) in 1994. Spielberg has purchased Academy Award statuettes being sold on the open market and donated them to the Academy of Motion Picture Arts and Sciences, to prevent their further commercial exploitation. His donations include the Oscars that Bette Davis received for Dangerous (1935) and Jezebel (1938), and Clark Gable's Oscar for It Happened One Night (1934).\",\n",
              " 'A combination of urban and suburban development, the West Side is generally defined as the area west of I-10. Western Tucson encompasses the banks of the Santa Cruz River and the foothills of the Tucson Mountains, and includes the International Wildlife Museum, Sentinel Peak, and the Marriott Starr Pass Resort & Spa, located in the wealthy enclave known as Starr Pass. Moving past the Tucson Mountains, travelers find themselves in the area commonly referred to as \"west of\" Tucson or \"Old West Tucson\". A large undulating plain extending south into the Altar Valley, rural residential development predominates, but here you will also find major attractions including Saguaro National Park West, the Arizona-Sonora Desert Museum, and the Old Tucson Studios movie set/theme park.',\n",
              " 'A combined UN civilian and peace-keeping force called UNTAG (United Nations Transition Assistance Group) under Finnish diplomat Martti Ahtisaari was deployed from April 1989 to March 1990 to monitor the peace process, elections and supervise military withdrawals. As UNTAG began to deploy peacekeepers, military observers, police, and political workers, hostilities were briefly renewed on the day the transition process was supposed to begin. After a new round of negotiations, a second date was set and the elections process began in earnest. After the return of SWAPO exiles (over 46,000 exiles), Namibia\\'s first one-person one-vote elections for the constitutional assembly took place in November 1989. The official election slogan was \"Free and Fair Elections\". This was won by SWAPO although it did not gain the two-thirds majority it had hoped for; the South African-backed Democratic Turnhalle Alliance (DTA) became the official opposition. The elections were peaceful and declared free and fair.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUyheBBjYcHT"
      },
      "source": [
        "# negative mining loss oriented data loader\r\n",
        "\r\n",
        "class IRDataset(tf.keras.utils.Sequence):\r\n",
        "    def __init__(self, df, batch_size):\r\n",
        "        self.df = df\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.uniq_passages = df_bert.loc[df.index].groupby('passage').groups\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.uniq_passages)//self.batch_size\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        keys = list(self.uniq_passages.keys())[idx * self.batch_size : (idx + 1) * self.batch_size]\r\n",
        "        id = []\r\n",
        "        for i in keys:\r\n",
        "            id.append(np.random.choice(self.uniq_passages[i]))\r\n",
        "\r\n",
        "        p = self.df['passage'].loc[id].tolist()\r\n",
        "        q = self.df['question'].loc[id].tolist()\r\n",
        "\r\n",
        "        return (np.stack(p), np.stack(q)), np.identity(self.batch_size)\r\n",
        "        '''\r\n",
        "        attention_mask_q = np.stack(q)\r\n",
        "        attention_mask_q[attention_mask_q != 0] = 1\r\n",
        "        attention_mask_p = np.stack(p)\r\n",
        "        attention_mask_p[attention_mask_p != 0] = 1\r\n",
        "        # if len(p) == 0 or len(q) == 0:\r\n",
        "        #     return ([], []), []\r\n",
        "\r\n",
        "        # original = df_bert.loc[self.df.index]\r\n",
        "        # unique_passage = df_bert.loc[self.df.index]['passage'].unique()\r\n",
        "        # print(unique_passage)\r\n",
        "        notp = []\r\n",
        "        for index in range(idx * self.batch_size,(idx + 1) * self.batch_size):\r\n",
        "            title = self.df[\"title\"].iloc[index]\r\n",
        "            passage = self.df[\"passage\"].iloc[index]\r\n",
        "            group = self.groups[title]\r\n",
        "            new_group = []\r\n",
        "            for id in group:\r\n",
        "                if self.df[\"passage\"][id] != passage:\r\n",
        "                    new_group.append(id)\r\n",
        "            notp.append(self.df[\"passage\"][np.random.choice(new_group)])\r\n",
        "        #print(f\"notp: {len(notp)}\")\r\n",
        "        #not_p = groups[]\r\n",
        "        # DA SISTEMARE; CI POTREBBERO ESSERE ANCORA I PASSAGGI GIUSTI PERCHè SONO RIPETUTI\r\n",
        "        all_not_p = list(range(0,idx * self.batch_size)) + list(range((idx + 1) * self.batch_size, len(self.df)))\r\n",
        "        #print(all_not_p)\r\n",
        "        rnd = np.random.choice(all_not_p, self.batch_size)                                #####################################################################################################\r\n",
        "        #print(f\"rnd is {rnd}\")\r\n",
        "        #notp = self.df['passage'].iloc[rnd].tolist()\r\n",
        "        attention_mask_not_p = np.stack(notp)\r\n",
        "        attention_mask_not_p[attention_mask_not_p != 0] = 1\r\n",
        "        #print(f\"notp is {notp}\")\r\n",
        "        y = half*[1]+half*[0]\r\n",
        "        #print(np.stack(p+notp))\r\n",
        "        return (np.stack(p+notp),np.vstack((attention_mask_p,attention_mask_not_p)), np.stack(q+q),np.vstack((attention_mask_q,attention_mask_q))), np.array(y)\r\n",
        "        #y = half*[1]+half*[1]\r\n",
        "        #return (np.stack(p+p),np.vstack((attention_mask_p,attention_mask_p)), np.stack(q+q),np.vstack((attention_mask_q,attention_mask_q))), np.array(y)\r\n",
        "        '''\r\n",
        "split_value = 0.1 \r\n",
        "val_dim = int(len(df_bert_preprocessed['title'].unique()) * split_value)\r\n",
        "val_titles = np.random.choice(df_bert_preprocessed['title'].unique(), size=val_dim, replace=False)\r\n",
        "\r\n",
        "df_bert_val = df_bert_preprocessed[df_bert_preprocessed['title'].isin(val_titles)]\r\n",
        "df_bert_train = df_bert_preprocessed[~(df_bert_preprocessed['title'].isin(val_titles))]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMy65yyBp-78",
        "outputId": "ca30aeab-d7be-4f32-f265-b628b790a6e0"
      },
      "source": [
        "seq_train = IRDataset(df_bert_train, 16)\r\n",
        "seq_train.__getitem__(0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[ 101, 2660, 1024, ...,    0,    0,    0],\n",
              "         [ 101, 2859, 1024, ...,    0,    0,    0],\n",
              "         [ 101, 2605, 1024, ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101, 6504, 1024, ...,    0,    0,    0],\n",
              "         [ 101, 4977, 1024, ...,    0,    0,    0],\n",
              "         [ 101, 1037, 4962, ...,    0,    0,    0]]),\n",
              "  array([[  101,  2073,  2001, ...,     0,     0,     0],\n",
              "         [  101,  2054,  4118, ...,     0,     0,     0],\n",
              "         [  101,  2073,  3295, ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  2040,  2020, ...,     0,     0,     0],\n",
              "         [  101,  2040, 11456, ...,     0,     0,     0],\n",
              "         [  101,  2054,  2003, ...,     0,     0,     0]])),\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwVwRBxzKwep",
        "outputId": "513481db-87b4-4046-fa96-db5f4c6b025f"
      },
      "source": [
        "#@title model definition { form-width: \"25%\" }\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import cosine_similarity, MSE, mae\n",
        "\n",
        "input_passage_ids = tf.keras.layers.Input(batch_input_shape=(16,max_seq_length,), dtype=tf.int32, name='input_passage_ids')\n",
        "input_question_ids = tf.keras.layers.Input(batch_input_shape=(16,max_seq_length,), dtype=tf.int32, name='input_question_ids')\n",
        "\n",
        "bert_hf_layer = transformers.TFElectraModel.from_pretrained(pretrained_model_str)\n",
        "\n",
        "passage_encoding = bert_hf_layer(input_ids=[input_passage_ids]).last_hidden_state[:,0]\n",
        "question_encoding = bert_hf_layer(input_ids=[input_question_ids]).last_hidden_state[:,0]\n",
        "\n",
        "densep = tf.keras.layers.Dense(256)\n",
        "denseq = tf.keras.layers.Dense(256)\n",
        "\n",
        "outp = densep(passage_encoding)\n",
        "outq = denseq(question_encoding)\n",
        "\n",
        "#dot = tf.keras.layers.Dot((0,0))\n",
        "outdot = tf.tensordot(outp, outq, axes=(1,1))\n",
        "\n",
        "softmax = tf.keras.layers.Softmax(axis=0)\n",
        "output = softmax(outdot)\n",
        "\n",
        "model = keras.Model(inputs=[input_passage_ids, input_question_ids], \n",
        "                    outputs=output,\n",
        "                    name=\"BERT_IR\")\n",
        "\n",
        "model.summary(line_length=150)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at google/electra-small-discriminator were not used when initializing TFElectraModel: ['discriminator_predictions']\n",
            "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-small-discriminator.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Model: \"BERT_IR\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
            "======================================================================================================================================================\n",
            "input_passage_ids (InputLayer)                   [(16, 512)]                      0                                                                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "input_question_ids (InputLayer)                  [(16, 512)]                      0                                                                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf_electra_model_12 (TFElectraModel)             TFBaseModelOutput(last_hidden_st 13483008          input_passage_ids[0][0]                           \n",
            "                                                                                                    input_question_ids[0][0]                          \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_22 (SlicingOpLambda)    (16, 256)                        0                 tf_electra_model_12[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_23 (SlicingOpLambda)    (16, 256)                        0                 tf_electra_model_12[1][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_22 (Dense)                                 (16, 256)                        65792             tf.__operators__.getitem_22[0][0]                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_23 (Dense)                                 (16, 256)                        65792             tf.__operators__.getitem_23[0][0]                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf.tensordot_3 (TFOpLambda)                      (16, 16)                         0                 dense_22[0][0]                                    \n",
            "                                                                                                    dense_23[0][0]                                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "softmax_2 (Softmax)                              (16, 16)                         0                 tf.tensordot_3[0][0]                              \n",
            "======================================================================================================================================================\n",
            "Total params: 13,614,592\n",
            "Trainable params: 13,614,592\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaYw_ZnZmflK",
        "outputId": "5f4b923c-306e-4813-eacf-754be69973d2"
      },
      "source": [
        "#@title train { form-width: \"25%\" }\r\n",
        "\r\n",
        "from transformers.optimization_tf import AdamWeightDecay\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "\r\n",
        "batch_size = 16\r\n",
        "epochs = 200\r\n",
        "steps_per_epoch = 20\r\n",
        "\r\n",
        "seq_train = IRDataset(df_bert_train, batch_size)\r\n",
        "seq_val = IRDataset(df_bert_val, batch_size)\r\n",
        "\r\n",
        "saveDir = os.path.join(os.getcwd(), 'saved_models')\r\n",
        "if not os.path.isdir(saveDir):\r\n",
        "    os.makedirs(saveDir)\r\n",
        "chkpt = saveDir + '/squad_check.hdf5'\r\n",
        "\r\n",
        "es_cb = EarlyStopping(monitor='val_loss', patience=2,verbose=1, mode='auto')\r\n",
        "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, \r\n",
        "                        save_best_only=False, mode='auto', \r\n",
        "                        save_weights_only=True)\r\n",
        "callbacks = [es_cb, cp_cb]\r\n",
        "\r\n",
        "ENABLE_WANDB = False        #@param {type:\"boolean\"}\r\n",
        "wandb_experiment_name = \"HF_\" + bert_hf_layer.name  #@param {type: \"string\"}\r\n",
        "if ENABLE_WANDB:\r\n",
        "    !pip install wandb > /dev/null\r\n",
        "    !wandb login\r\n",
        "    import wandb\r\n",
        "    from wandb.keras import WandbCallback\r\n",
        "    wandb.init(project=\"SQUAD\", name=wandb_experiment_name)\r\n",
        "    wandb.config.batch_size = batch_size\r\n",
        "    wandb.config.epochs = epochs\r\n",
        "    callbacks.append(WandbCallback(log_batch_frequency=10,\r\n",
        "                                   save_weights_only=True))\r\n",
        "\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "optimizer = AdamWeightDecay(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\r\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics = \"accuracy\")\r\n",
        "history = model.fit(seq_train, epochs=epochs,\r\n",
        "                    callbacks=callbacks, \r\n",
        "                    validation_data=seq_val,\r\n",
        "                    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1055/1055 [==============================] - ETA: 0s - loss: 3.3758 - accuracy: 0.0601WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1055/1055 [==============================] - 544s 504ms/step - loss: 3.3755 - accuracy: 0.0601 - val_loss: 2.7716 - val_accuracy: 0.0852\n",
            "\n",
            "Epoch 00001: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 2/200\n",
            "1055/1055 [==============================] - 530s 502ms/step - loss: 2.7859 - accuracy: 0.0663 - val_loss: 2.2625 - val_accuracy: 0.2324\n",
            "\n",
            "Epoch 00002: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 3/200\n",
            "1055/1055 [==============================] - 530s 502ms/step - loss: 2.2203 - accuracy: 0.2406 - val_loss: 1.6643 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 00003: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 4/200\n",
            "1055/1055 [==============================] - 530s 502ms/step - loss: 1.6547 - accuracy: 0.4451 - val_loss: 1.4555 - val_accuracy: 0.5408\n",
            "\n",
            "Epoch 00004: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 5/200\n",
            "1055/1055 [==============================] - 530s 503ms/step - loss: 1.3957 - accuracy: 0.5489 - val_loss: 1.1791 - val_accuracy: 0.6336\n",
            "\n",
            "Epoch 00005: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 6/200\n",
            "1055/1055 [==============================] - 530s 502ms/step - loss: 1.1924 - accuracy: 0.6175 - val_loss: 1.1006 - val_accuracy: 0.6603\n",
            "\n",
            "Epoch 00006: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 7/200\n",
            "1055/1055 [==============================] - 530s 502ms/step - loss: 1.1203 - accuracy: 0.6477 - val_loss: 1.0974 - val_accuracy: 0.6769\n",
            "\n",
            "Epoch 00007: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 8/200\n",
            "1055/1055 [==============================] - 530s 502ms/step - loss: 0.9936 - accuracy: 0.6873 - val_loss: 0.9786 - val_accuracy: 0.7011\n",
            "\n",
            "Epoch 00008: saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 9/200\n",
            "  27/1055 [..............................] - ETA: 8:18 - loss: 0.8827 - accuracy: 0.7466"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvY5enaZ2Oio",
        "outputId": "f07c23d2-882e-4170-e985-abe1facbd910"
      },
      "source": [
        "# CELLA DI PROVA INFERENCE\r\n",
        "#@title inference model PROVA { form-width: \"25%\" }\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "batch_size = 16\r\n",
        "\r\n",
        "all_encodings = []\r\n",
        "\r\n",
        "for idx in tqdm(range(len(df_bert_val)//batch_size)):\r\n",
        "    questions = df_bert_val['question'].iloc[idx * batch_size : (idx + 1) * batch_size].tolist()\r\n",
        "    attention_mask_questions = np.stack(questions)\r\n",
        "    attention_mask_questions[attention_mask_questions != 0] = 1\r\n",
        "    passages = df_bert_val['passage'].iloc[idx * batch_size : (idx + 1) * batch_size].tolist()\r\n",
        "    attention_mask_passages = np.stack(passages)\r\n",
        "    attention_mask_passages[attention_mask_passages != 0] = 1\r\n",
        "    encodings = model.predict([np.stack(passages), attention_mask_passages, np.stack(questions), attention_mask_questions])\r\n",
        "    all_encodings.append(encodings)\r\n",
        "    break\r\n",
        "    # encoded_val_passage[i*batch_size : (i+1)*batch_size] = inf_model(passages[i*batch_size : (i+1)*batch_size])\r\n",
        "    # encoded_val_question[i*batch_size : (i+1)*batch_size] = inf_model(questions[i*batch_size : (i+1)*batch_size])\r\n",
        "\r\n",
        "#print(encodings.shape)\r\n",
        "\r\n",
        "# all_encodings_arr = np.vstack(all_encodings)\r\n",
        "# encoding_passages = all_encodings_arr[:,:,0]\r\n",
        "# encoding_questions = all_encodings_arr[:,:,1]\r\n",
        "\r\n",
        "encoding_passages = encodings[:,:,0]\r\n",
        "encoding_questions = encodings[:,:,1]\r\n",
        "first_passage_encoding = encoding_passages[0]\r\n",
        "first_question_encoding = encoding_questions[0]\r\n",
        "#print(first_passage_encoding.reshape(1,-1).shape)\r\n",
        "print(cosine_similarity(first_question_encoding.reshape(1,-1),first_passage_encoding.reshape(1,-1)))\r\n",
        "#print(cosine_similarity(encoding_questions, encoding_passages))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/446 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-0.0657178]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1t64RBc-l1m",
        "outputId": "9e3f3efe-33f9-4e03-9185-4987ae5b3f58"
      },
      "source": [
        "# SECONDA CELLA PROVA INFERENCE\r\n",
        "cos_sim = cosine_similarity(encoding_questions, encoding_passages)\r\n",
        "print(np.argmax(cos_sim[878]))\r\n",
        "ok=0\r\n",
        "for i in range(7136):   # i is the question index\r\n",
        "    best = np.argmax(cos_sim[i])\r\n",
        "    if np.array_equal(df_bert_val.iloc[i].passage, df_bert_val.iloc[best].passage):\r\n",
        "        ok+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "960XIu-EOCw5",
        "outputId": "ed551ac7-9885-4790-e454-8c2e2573573b"
      },
      "source": [
        "len(df_bert_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON3n92Y0DtNm",
        "outputId": "19916953-01ca-4694-ba71-ea28f1db6db3"
      },
      "source": [
        "print(ok/7136)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0008408071748878924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYH_YkJKFI2o",
        "outputId": "020e00d8-2a7c-4c83-c545-4edec5554b1b"
      },
      "source": [
        "print(cos_sim[0][:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.94073474 0.94073474 0.94073474 0.94073474 0.94073474 0.94073474\n",
            " 0.94073474 0.94073474 0.940735   0.940735   0.940735   0.940735\n",
            " 0.940735   0.940735   0.940735   0.940735   0.940735   0.940735\n",
            " 0.940735   0.940735   0.9222013  0.9222013  0.9222013  0.9222013\n",
            " 0.9222013  0.9222013  0.9222013  0.9222013  0.9222013  0.9222013\n",
            " 0.9222013  0.9222013  0.8756785  0.8756785  0.8756785  0.8756785\n",
            " 0.8756785  0.8756785  0.8756785  0.8756785  0.8756785  0.8756785\n",
            " 0.8756785  0.8756785  0.7282998  0.7282998  0.7282998  0.7282998\n",
            " 0.7282998  0.7282998  0.7282998  0.7282998  0.7282998  0.7282998\n",
            " 0.7282998  0.7282998  0.7282998  0.71472895 0.71472895 0.71472895\n",
            " 0.71472895 0.71472895 0.71472895 0.71472895 0.71472895 0.71472895\n",
            " 0.71472895 0.71472895 0.95767933 0.95767933 0.95767933 0.95767933\n",
            " 0.95767933 0.95767933 0.95767933 0.95767933 0.95767933 0.95767933\n",
            " 0.95767933 0.95767933 0.95767933 0.96482575 0.96482575 0.96482575\n",
            " 0.96482575 0.96482575 0.96482575 0.96482575 0.96482575 0.96482575\n",
            " 0.96482575 0.96482575 0.96482575 0.96482575 0.78409016 0.78409016\n",
            " 0.78409016 0.78409016 0.78409016 0.78409016]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zdI3LLkoFUJP",
        "outputId": "86d1507c-5034-4a65-8a78-67744937640d"
      },
      "source": [
        "df_bert_val.iloc[:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_idx</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56be85543aeaaa14008c9063</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, ...]</td>\n",
              "      <td>[101, 2043, 2106, 20773, 2707, 3352, 2759, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(269, 286)</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56be85543aeaaa14008c9065</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, ...]</td>\n",
              "      <td>[101, 2054, 2752, 2106, 20773, 5566, 1999, 2043, 2016, 2001, 3652, 2039, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(207, 226)</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56be85543aeaaa14008c9066</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, ...]</td>\n",
              "      <td>[101, 2043, 2106, 20773, 2681, 10461, 1005, 1055, 2775, 1998, 2468, 1037, 3948, 3220, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(526, 530)</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56bf6b0f3aeaaa14008c9601</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, ...]</td>\n",
              "      <td>[101, 1999, 2054, 2103, 1998, 2110, 2106, 20773, 4982, 2039, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(166, 180)</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56bf6b0f3aeaaa14008c9602</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, ...]</td>\n",
              "      <td>[101, 1999, 2029, 5476, 2106, 20773, 2468, 3297, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(276, 286)</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56be8d423aeaaa14008c90b3</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 24543, 3148, 6735, 6582, 1998, 11111, 17753, 2150, 12511, 2007, 25436, 1005, 1055, 6605, 1997, 1996, 2316, 1998, 2776, 2020, 2999, 2011, 2521, 10404, 5951, 1998, 9393, 3766, 1012, 20773, 5281, 6245, 2206, 1996, 3975, 2007, 6735, 6582, 1998, 11111, 17753, 2044, 2108, 7271, 11248, 2011, 1996, 2865, 1010, 4401, 1010, 1998, 23012, 2005, 2049, 3426, 1012, 2014, 2146, 1011, 3061, 6898, 2187, 2014, 2012, 2023, 2051, 1012, 1996, 6245, 2001, 2061, 5729, 2009, 6354, 2005, 1037, 3232, 1997, 2086, 1010, 2076, 2029, 2016, 5681, 2921, 2841, 1999, 2014, 5010, 2005, 2420, 1998, 4188, 2000, 4521, 2505, 1012, 20773, ...]</td>\n",
              "      <td>[101, 2054, 2724, 5258, 2098, 2044, 2016, 2001, 7271, 6367, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(320, 338)</td>\n",
              "      <td>boyfriend left her</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56be8d423aeaaa14008c90b6</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 24543, 3148, 6735, 6582, 1998, 11111, 17753, 2150, 12511, 2007, 25436, 1005, 1055, 6605, 1997, 1996, 2316, 1998, 2776, 2020, 2999, 2011, 2521, 10404, 5951, 1998, 9393, 3766, 1012, 20773, 5281, 6245, 2206, 1996, 3975, 2007, 6735, 6582, 1998, 11111, 17753, 2044, 2108, 7271, 11248, 2011, 1996, 2865, 1010, 4401, 1010, 1998, 23012, 2005, 2049, 3426, 1012, 2014, 2146, 1011, 3061, 6898, 2187, 2014, 2012, 2023, 2051, 1012, 1996, 6245, 2001, 2061, 5729, 2009, 6354, 2005, 1037, 3232, 1997, 2086, 1010, 2076, 2029, 2016, 5681, 2921, 2841, 1999, 2014, 5010, 2005, 2420, 1998, 4188, 2000, 4521, 2505, 1012, 20773, ...]</td>\n",
              "      <td>[101, 2040, 3569, 20773, 2083, 2014, 6245, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(714, 724)</td>\n",
              "      <td>her mother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56bf7e603aeaaa14008c9682</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 24543, 3148, 6735, 6582, 1998, 11111, 17753, 2150, 12511, 2007, 25436, 1005, 1055, 6605, 1997, 1996, 2316, 1998, 2776, 2020, 2999, 2011, 2521, 10404, 5951, 1998, 9393, 3766, 1012, 20773, 5281, 6245, 2206, 1996, 3975, 2007, 6735, 6582, 1998, 11111, 17753, 2044, 2108, 7271, 11248, 2011, 1996, 2865, 1010, 4401, 1010, 1998, 23012, 2005, 2049, 3426, 1012, 2014, 2146, 1011, 3061, 6898, 2187, 2014, 2012, 2023, 2051, 1012, 1996, 6245, 2001, 2061, 5729, 2009, 6354, 2005, 1037, 3232, 1997, 2086, 1010, 2076, 2029, 2016, 5681, 2921, 2841, 1999, 2014, 5010, 2005, 2420, 1998, 4188, 2000, 4521, 2505, 1012, 20773, ...]</td>\n",
              "      <td>[101, 2129, 2146, 2001, 20773, 14777, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(396, 413)</td>\n",
              "      <td>a couple of years</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56bf7e603aeaaa14008c9685</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 24543, 3148, 6735, 6582, 1998, 11111, 17753, 2150, 12511, 2007, 25436, 1005, 1055, 6605, 1997, 1996, 2316, 1998, 2776, 2020, 2999, 2011, 2521, 10404, 5951, 1998, 9393, 3766, 1012, 20773, 5281, 6245, 2206, 1996, 3975, 2007, 6735, 6582, 1998, 11111, 17753, 2044, 2108, 7271, 11248, 2011, 1996, 2865, 1010, 4401, 1010, 1998, 23012, 2005, 2049, 3426, 1012, 2014, 2146, 1011, 3061, 6898, 2187, 2014, 2012, 2023, 2051, 1012, 1996, 6245, 2001, 2061, 5729, 2009, 6354, 2005, 1037, 3232, 1997, 2086, 1010, 2076, 2029, 2016, 5681, 2921, 2841, 1999, 2014, 5010, 2005, 2420, 1998, 4188, 2000, 4521, 2505, 1012, 20773, ...]</td>\n",
              "      <td>[101, 2040, 3271, 20773, 2954, 2014, 6245, 1996, 2087, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(714, 724)</td>\n",
              "      <td>her mother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56d462f82ccc5a1400d8311f</th>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>[101, 24543, 3148, 6735, 6582, 1998, 11111, 17753, 2150, 12511, 2007, 25436, 1005, 1055, 6605, 1997, 1996, 2316, 1998, 2776, 2020, 2999, 2011, 2521, 10404, 5951, 1998, 9393, 3766, 1012, 20773, 5281, 6245, 2206, 1996, 3975, 2007, 6735, 6582, 1998, 11111, 17753, 2044, 2108, 7271, 11248, 2011, 1996, 2865, 1010, 4401, 1010, 1998, 23012, 2005, 2049, 3426, 1012, 2014, 2146, 1011, 3061, 6898, 2187, 2014, 2012, 2023, 2051, 1012, 1996, 6245, 2001, 2061, 5729, 2009, 6354, 2005, 1037, 3232, 1997, 2086, 1010, 2076, 2029, 2016, 5681, 2921, 2841, 1999, 2014, 5010, 2005, 2420, 1998, 4188, 2000, 4521, 2505, 1012, 20773, ...]</td>\n",
              "      <td>[101, 2040, 2999, 6735, 6582, 1998, 11111, 17753, 1999, 10461, 1005, 1055, 2775, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(110, 148)</td>\n",
              "      <td>Farrah Franklin and Michelle Williams.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            title  ...                             answer_text\n",
              "id                                 ...                                        \n",
              "56be85543aeaaa14008c9063  Beyoncé  ...  in the late 1990s                     \n",
              "56be85543aeaaa14008c9065  Beyoncé  ...  singing and dancing                   \n",
              "56be85543aeaaa14008c9066  Beyoncé  ...  2003                                  \n",
              "56bf6b0f3aeaaa14008c9601  Beyoncé  ...  Houston, Texas                        \n",
              "56bf6b0f3aeaaa14008c9602  Beyoncé  ...  late 1990s                            \n",
              "...                           ...  ...             ...                        \n",
              "56be8d423aeaaa14008c90b3  Beyoncé  ...  boyfriend left her                    \n",
              "56be8d423aeaaa14008c90b6  Beyoncé  ...  her mother                            \n",
              "56bf7e603aeaaa14008c9682  Beyoncé  ...  a couple of years                     \n",
              "56bf7e603aeaaa14008c9685  Beyoncé  ...  her mother                            \n",
              "56d462f82ccc5a1400d8311f  Beyoncé  ...  Farrah Franklin and Michelle Williams.\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfifQk2BBbKL",
        "outputId": "7eb4e976-3b3f-4207-d856-34e9c194720f"
      },
      "source": [
        "# TERZA CELLA PROVA INFERENCE\r\n",
        "df_bert_val.iloc[3034]\r\n",
        "df_bert.loc[\"571a48c110f8ca1400304fc7\"]\r\n",
        "# When did Beyonce start becoming popular? \r\n",
        "# Who began producing Oswald cartoons for Universal in 1929?  \r\n",
        "#What is another term for specific formal prescriptions?   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title          Memory                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
              "passage        The working memory model explains many practical observations, such as why it is easier to do two different tasks (one verbal and one visual) than two similar tasks (e.g., two visual), and the aforementioned word-length effect. However, the concept of a central executive as noted here has been criticised as inadequate and vague.[citation needed] Working memory is also the premise for what allows us to do everyday activities involving thought. It is the section of memory where we carry out thought processes and use them to learn and reason about topics.\n",
              "question       Which model explains why bob has an easier time reading a book, and then discussing it rather than reading two books?                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
              "answer_idx     (4, 24)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "answer_text    working memory model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
              "Name: 571a48c110f8ca1400304fc7, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "fpH1ADf0LrKC",
        "outputId": "ea4df645-72c1-406a-a70a-fa49b6820009"
      },
      "source": [
        "#@title inference model { form-width: \"25%\" }\r\n",
        "\r\n",
        "input_txt_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32)\r\n",
        "output = bert_hf_layer(input_ids=input_txt_ids).last_hidden_state[:,0]\r\n",
        "inf_model = keras.Model(inputs=input_txt_ids, outputs=output, name=\"BERT_IR\")\r\n",
        "\r\n",
        "encoded_val_passage = np.zeros((len(df_bert_val), 256))\r\n",
        "encoded_val_question = np.zeros((len(df_bert_val), 256))\r\n",
        "passages = np.stack(df_bert_val['passage'])\r\n",
        "questions = np.stack(df_bert_val['question'])\r\n",
        "\r\n",
        "\r\n",
        "for i in tqdm(range(len(df_bert_val)//batch_size)):\r\n",
        "    encoded_val_passage[i*batch_size : (i+1)*batch_size] = inf_model(passages[i*batch_size : (i+1)*batch_size])\r\n",
        "    encoded_val_question[i*batch_size : (i+1)*batch_size] = inf_model(questions[i*batch_size : (i+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 61%|██████    | 325/531 [01:29<00:57,  3.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-e277a8c5947e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_bert_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mencoded_val_passage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mencoded_val_question\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21bEK6SuLRk2",
        "outputId": "1e225cdf-39f6-4b16-a98e-66bdb7c766cb"
      },
      "source": [
        "#@title kNN cosine similarity { form-width: \"25%\" }\r\n",
        "\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "from sklearn.neighbors import NearestNeighbors\r\n",
        "\r\n",
        "k=1\r\n",
        "tree = NearestNeighbors(n_neighbors=k, metric='cosine')\r\n",
        "tree.fit(encoded_val_passage)\r\n",
        "\r\n",
        "results = tree.kneighbors(encoded_val_question, n_neighbors=k, return_distance=False)\r\n",
        "\r\n",
        "ok=0\r\n",
        "for i in range(len(df_bert_val)):\r\n",
        "    for j in range(k):\r\n",
        "        if np.array_equal(passages[results[i,j]], passages[i]):\r\n",
        "            ok+=1\r\n",
        "\r\n",
        "ok/len(df_bert_val)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05595970900951316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJay6V8RYWtF",
        "outputId": "c62e85b8-4c40-4234-9869-e700b445378d"
      },
      "source": [
        "results[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1213, 1210, 1212, 1211, 1675])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJSpeKm_jsmO"
      },
      "source": [
        "!pip3 install wikipedia-api\r\n",
        "\r\n",
        "import wikipediaapi\r\n",
        "wiki_wiki = wikipediaapi.Wikipedia('en')\r\n",
        "cat = wiki_wiki.page(\"Category:Physics\")\r\n",
        "print(\"Category members: Category:Physics\")\r\n",
        "for p in cat.categorymembers.values():\r\n",
        "  if p.namespace == wikipediaapi.Namespace.CATEGORY:\r\n",
        "    # it is category, so you have to make decision\r\n",
        "    # if you want to fetch also text from pages that belong\r\n",
        "    # to this category\r\n",
        "    print(p)\r\n",
        "  elif p.namespace == wikipediaapi.Namespace.MAIN:\r\n",
        "    # it is page => we can get text\r\n",
        "    print(p)\r\n",
        "    print(p.text)\r\n",
        "\r\n",
        "def print_categorymembers(categorymembers, level=0, max_level=3):\r\n",
        "        for c in categorymembers.values():\r\n",
        "            print(\"%s: %s (ns: %d)\" % (\"*\" * (level + 1), c.title, c.ns))\r\n",
        "            if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level:\r\n",
        "                print_categorymembers(c.categorymembers, level=level + 1, max_level=max_level)\r\n",
        "\r\n",
        "cat = wiki_wiki.page(\"Category:Artificial intelligence\")\r\n",
        "print_categorymembers(cat.categorymembers)\r\n",
        "\r\n",
        "wiki_wiki = wikipediaapi.Wikipedia('en')\r\n",
        "\r\n",
        "page_py = wiki_wiki.page('Python_(programming_language)')\r\n",
        "print(page_py.text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}