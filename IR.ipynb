{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "170978ee663a4eb19aa37aff1c216eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a5b6363aee14ff884e4cc8250cc9b57",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ccf0dbe7bf044a2b37d7de4e23d2e1e",
              "IPY_MODEL_3e3abd156cb0463090dbda98a1effd1f"
            ]
          }
        },
        "3a5b6363aee14ff884e4cc8250cc9b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ccf0dbe7bf044a2b37d7de4e23d2e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4cde0a17e1dd45e3b7d70507b0a43134",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5903e809cc4c424b8cecca2b148d1ad0"
          }
        },
        "3e3abd156cb0463090dbda98a1effd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69b8d1da55d94861a8ba64af46b347c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466/466 [00:00&lt;00:00, 7.97kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8046de26f8a74d0db5e281855f4bfcc4"
          }
        },
        "4cde0a17e1dd45e3b7d70507b0a43134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5903e809cc4c424b8cecca2b148d1ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69b8d1da55d94861a8ba64af46b347c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8046de26f8a74d0db5e281855f4bfcc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c848b3f464b549dfb8b558215d0e05cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f41574a900874251b608519ff1814660",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10423ebbdd3b4c31b98cbbce09bbe911",
              "IPY_MODEL_056e84eda0ee4b41854d438218ee7da6"
            ]
          }
        },
        "f41574a900874251b608519ff1814660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10423ebbdd3b4c31b98cbbce09bbe911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35991467a2a04442aa0319b13b8bac34",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 54466044,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 54466044,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2156a7118abe42c48fc3698e4691bf9b"
          }
        },
        "056e84eda0ee4b41854d438218ee7da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_602da72c6d7a4aae9319f05d95082e61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 54.5M/54.5M [00:01&lt;00:00, 37.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d70ecca64c6d4815b8c3c67688891887"
          }
        },
        "35991467a2a04442aa0319b13b8bac34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2156a7118abe42c48fc3698e4691bf9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "602da72c6d7a4aae9319f05d95082e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d70ecca64c6d4815b8c3c67688891887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55c7e709b69a450ca5661c4fe359d4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c55c612481b4ce589f01b854ed6347a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8e107166ff4412c8f56aeb4e7086645",
              "IPY_MODEL_d850c4757e724b4aa866dd40654ef3ca"
            ]
          }
        },
        "6c55c612481b4ce589f01b854ed6347a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8e107166ff4412c8f56aeb4e7086645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ecc934f0fca04fe99c9a2a5afccb6813",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fe21a308ceb47eca46cedcd16252407"
          }
        },
        "d850c4757e724b4aa866dd40654ef3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c08cff46d3046b9898f5e6cfe9fe061",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 790kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cceda39829a44d43a6066e2e583027e3"
          }
        },
        "ecc934f0fca04fe99c9a2a5afccb6813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fe21a308ceb47eca46cedcd16252407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c08cff46d3046b9898f5e6cfe9fe061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cceda39829a44d43a6066e2e583027e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aaa79b124fe04b3b998b61d6da9abff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_398ca59a38fb4082bb8a3cbf8539d09c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_237344f05762495f99954b3ec99698ab",
              "IPY_MODEL_e64d1ad248b044d7b634f88acc7472f8"
            ]
          }
        },
        "398ca59a38fb4082bb8a3cbf8539d09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "237344f05762495f99954b3ec99698ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0c8a40c42a24e56879abb4ad7d40cb0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3041e4aceb2b4d8e822852984de393f2"
          }
        },
        "e64d1ad248b044d7b634f88acc7472f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7c520112603421ea74116a6ed10b971",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72cd234bf5ce456ea3c74343e7706ffe"
          }
        },
        "a0c8a40c42a24e56879abb4ad7d40cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3041e4aceb2b4d8e822852984de393f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7c520112603421ea74116a6ed10b971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72cd234bf5ce456ea3c74343e7706ffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-SQuAD-squad/IR/blob/electra/IR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QeSehvkoMtT"
      },
      "source": [
        "DA FARE: \r\n",
        "-Sistemare dataset in modo che le coppie domanda passaggio siano giuste\r\n",
        "-Provare modello dense, senza trainare Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "170978ee663a4eb19aa37aff1c216eaf",
            "3a5b6363aee14ff884e4cc8250cc9b57",
            "3ccf0dbe7bf044a2b37d7de4e23d2e1e",
            "3e3abd156cb0463090dbda98a1effd1f",
            "4cde0a17e1dd45e3b7d70507b0a43134",
            "5903e809cc4c424b8cecca2b148d1ad0",
            "69b8d1da55d94861a8ba64af46b347c5",
            "8046de26f8a74d0db5e281855f4bfcc4",
            "c848b3f464b549dfb8b558215d0e05cf",
            "f41574a900874251b608519ff1814660",
            "10423ebbdd3b4c31b98cbbce09bbe911",
            "056e84eda0ee4b41854d438218ee7da6",
            "35991467a2a04442aa0319b13b8bac34",
            "2156a7118abe42c48fc3698e4691bf9b",
            "602da72c6d7a4aae9319f05d95082e61",
            "d70ecca64c6d4815b8c3c67688891887",
            "55c7e709b69a450ca5661c4fe359d4e0",
            "6c55c612481b4ce589f01b854ed6347a",
            "c8e107166ff4412c8f56aeb4e7086645",
            "d850c4757e724b4aa866dd40654ef3ca",
            "ecc934f0fca04fe99c9a2a5afccb6813",
            "1fe21a308ceb47eca46cedcd16252407",
            "8c08cff46d3046b9898f5e6cfe9fe061",
            "cceda39829a44d43a6066e2e583027e3",
            "aaa79b124fe04b3b998b61d6da9abff4",
            "398ca59a38fb4082bb8a3cbf8539d09c",
            "237344f05762495f99954b3ec99698ab",
            "e64d1ad248b044d7b634f88acc7472f8",
            "a0c8a40c42a24e56879abb4ad7d40cb0",
            "3041e4aceb2b4d8e822852984de393f2",
            "f7c520112603421ea74116a6ed10b971",
            "72cd234bf5ce456ea3c74343e7706ffe"
          ]
        },
        "id": "wFibP1RFJ2jZ",
        "outputId": "fdd93fba-9a75-4f7b-bc95-501f858d437d"
      },
      "source": [
        "#@title Init { form-width: \"25%\" }\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "!pip install tokenizers\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "# fix random seeds\n",
        "seed_value = 42 #@param {type:\"integer\"}\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "tf.compat.v1.set_random_seed(seed_value)\n",
        "\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "# BERT params\n",
        "max_seq_length = 512\n",
        "# Huggingface bert and associated tokenizer\n",
        "pretrained_model_str = \"google/electra-small-discriminator\"\n",
        "bert_hf_layer = transformers.TFElectraModel.from_pretrained(\n",
        "    pretrained_model_str, output_attentions=True)\n",
        "\n",
        "#pretrained_model_str = \"roberta-base\"\n",
        "#bert_hf_layer = transformers.TFRobertaModel.from_pretrained(\n",
        "    #pretrained_model_str, output_attentions=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_str)\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 20.2MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.1\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 17.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=c09e6f24e5c93ad4475354f9df00071e5d02db9cd86aa8f296fdb67bf5c7def9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 transformers-4.3.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "170978ee663a4eb19aa37aff1c216eaf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c848b3f464b549dfb8b558215d0e05cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=54466044.0, style=ProgressStyle(descripâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at google/electra-small-discriminator were not used when initializing TFElectraModel: ['discriminator_predictions']\n",
            "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-small-discriminator.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c7e709b69a450ca5661c4fe359d4e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaa79b124fe04b3b998b61d6da9abff4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Thu Feb 25 12:20:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    29W /  70W |    412MiB / 15109MiB |      2%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUGjp7aOKRyW",
        "outputId": "6013f80d-c80c-4480-b37c-53e159fd0576"
      },
      "source": [
        "#@title df creation { form-width: \"25%\" }\n",
        "\n",
        "# the official dataset is identical to the provided one\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json -O training_set.json\n",
        "\n",
        "with open(\"training_set.json\", \"r\") as f:\n",
        "    json_file = json.load(f)\n",
        "data = json_file[\"data\"]\n",
        "\n",
        "rows = []\n",
        "for document in data:\n",
        "  for par in document['paragraphs']:\n",
        "    for qas in par['qas']:\n",
        "      rows.append({\n",
        "        'id' : qas['id'],\n",
        "        'title': document[\"title\"],\n",
        "        'passage': par['context'],\n",
        "        'question' : qas['question'],\n",
        "        'answer_idx' : (qas['answers'][0]['answer_start'], \n",
        "                    qas['answers'][0]['answer_start'] + len(qas['answers'][0]['text'])),\n",
        "        'answer_text' : qas['answers'][0]['text']\n",
        "      })\n",
        "\n",
        "df_original = pd.DataFrame(rows)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-25 12:20:44--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.109.153, 185.199.111.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: â€˜training_set.jsonâ€™\n",
            "\n",
            "training_set.json   100%[===================>]  28.88M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-02-25 12:20:44 (218 MB/s) - â€˜training_set.jsonâ€™ saved [30288272/30288272]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "ssgBa3_tKpM8",
        "outputId": "4ea42892-71fe-4eda-d370-44dc95375272"
      },
      "source": [
        "#@title clean dataset { form-width: \"25%\" }\n",
        "\n",
        "!gcloud config set project feisty-mechanic-221914\n",
        "!gsutil cp gs://squad_squad/error_IDs.txt ./error_IDs.txt\n",
        "\n",
        "with open(\"error_IDs.txt\", \"r\") as f:\n",
        "    unwanted_id = f.read()\n",
        "\n",
        "unwanted_id = unwanted_id.split(\"\\n\")[:-1]\n",
        "df_bert = df_original.set_index('id')\n",
        "df_bert = df_bert.drop(unwanted_id)\n",
        "df_bert.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Copying gs://squad_squad/error_IDs.txt...\n",
            "/ [1 files][  5.7 KiB/  5.7 KiB]                                                \n",
            "Operation completed over 1 objects/5.7 KiB.                                      \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_idx</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661182</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
              "      <td>(515, 541)</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117f</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>(188, 213)</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661180</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame is beside to which structure?</td>\n",
              "      <td>(279, 296)</td>\n",
              "      <td>the Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661181</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>(381, 420)</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117e</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</td>\n",
              "      <td>What sits on top of the Main Building at Notre Dame?</td>\n",
              "      <td>(92, 126)</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             title  ...                              answer_text\n",
              "id                                                  ...                                         \n",
              "5733be284776f41900661182  University_of_Notre_Dame  ...  Saint Bernadette Soubirous             \n",
              "5733be284776f4190066117f  University_of_Notre_Dame  ...  a copper statue of Christ              \n",
              "5733be284776f41900661180  University_of_Notre_Dame  ...  the Main Building                      \n",
              "5733be284776f41900661181  University_of_Notre_Dame  ...  a Marian place of prayer and reflection\n",
              "5733be284776f4190066117e  University_of_Notre_Dame  ...  a golden statue of the Virgin Mary     \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "3NmgPXxseEZy",
        "outputId": "1088b5ad-3b5a-4ba4-9cde-db2b9f215c67"
      },
      "source": [
        "#@title BERT preprocessing { form-width: \"25%\" }\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "def preprocess_bert(text):\r\n",
        "    tokenized_text = tokenizer(list(text), padding=\"max_length\", max_length=max_seq_length, truncation=True)\r\n",
        "    return tokenized_text.input_ids\r\n",
        "\r\n",
        "df_bert_preprocessed = df_bert.copy()\r\n",
        "# pre-process passage and question text\r\n",
        "print(\"Preprocessing passage...\")\r\n",
        "df_bert_preprocessed['passage'] = preprocess_bert(df_bert['passage'])\r\n",
        "print(\"Preprocessing question...\")\r\n",
        "df_bert_preprocessed['question'] = preprocess_bert(df_bert['question'])\r\n",
        "df_bert_preprocessed.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing passage...\n",
            "Preprocessing question...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_idx</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661182</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(515, 541)</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117f</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2054, 2003, 1999, 2392, 1997, 1996, 10289, 8214, 2364, 2311, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(188, 213)</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661180</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 1996, 13546, 1997, 1996, 6730, 2540, 2012, 10289, 8214, 2003, 3875, 2000, 2029, 3252, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(279, 296)</td>\n",
              "      <td>the Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f41900661181</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2054, 2003, 1996, 24665, 23052, 2012, 10289, 8214, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(381, 420)</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5733be284776f4190066117e</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>[101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, ...]</td>\n",
              "      <td>[101, 2054, 7719, 2006, 2327, 1997, 1996, 2364, 2311, 2012, 10289, 8214, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>(92, 126)</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             title  ...                              answer_text\n",
              "id                                                  ...                                         \n",
              "5733be284776f41900661182  University_of_Notre_Dame  ...  Saint Bernadette Soubirous             \n",
              "5733be284776f4190066117f  University_of_Notre_Dame  ...  a copper statue of Christ              \n",
              "5733be284776f41900661180  University_of_Notre_Dame  ...  the Main Building                      \n",
              "5733be284776f41900661181  University_of_Notre_Dame  ...  a Marian place of prayer and reflection\n",
              "5733be284776f4190066117e  University_of_Notre_Dame  ...  a golden statue of the Virgin Mary     \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a821Zx41Knie",
        "outputId": "7a1ab7d3-ab73-4bd9-cbb3-ee3a844a91d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "title = np.random.choice(list(df_bert.groupby('title').groups.keys()))\r\n",
        "l = []\r\n",
        "for title in list(df_bert.groupby('title').groups.keys()):\r\n",
        "    all_passages_of_title = (df_bert[df_bert[\"title\"] == title])[\"passage\"].unique()\r\n",
        "    l.append(len(all_passages_of_title))\r\n",
        "\r\n",
        "min(l)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUyheBBjYcHT"
      },
      "source": [
        "# negative mining loss oriented data loader\r\n",
        "\r\n",
        "class IRDataset(tf.keras.utils.Sequence):\r\n",
        "    def __init__(self, df, batch_size):\r\n",
        "        self.df = df\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.df_bert = df_bert.loc[df.index]\r\n",
        "        self.uniq_passages = df_bert.loc[df.index].groupby('passage').groups\r\n",
        "        self.uniq_titles = df_bert.loc[df.index].groupby('title').groups\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        #return len(self.uniq_passages)//self.batch_size\r\n",
        "        return len(self.uniq_titles)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        #keys = list(self.uniq_passages.keys())[idx * self.batch_size : (idx + 1) * self.batch_size]\r\n",
        "        #title = np.random.choice(self.uniq_titles.keys())\r\n",
        "        title = list(self.uniq_titles.keys())[idx]\r\n",
        "        all_passages_of_title = (self.df_bert[self.df_bert[\"title\"] == title])[\"passage\"].unique()\r\n",
        "        id = []\r\n",
        "        if len(all_passages_of_title) >= self.batch_size:\r\n",
        "            passages =  np.random.choice(all_passages_of_title, self.batch_size)\r\n",
        "            for passage in passages:\r\n",
        "                id.append(np.random.choice(self.uniq_passages[passage]))\r\n",
        "        else:\r\n",
        "            for passage in all_passages_of_title: \r\n",
        "                id.append(np.random.choice(self.uniq_passages[passage]))\r\n",
        "            for i in range(self.batch_size-len(all_passages_of_title)):\r\n",
        "                new_title =  np.random.choice(list(self.uniq_titles.keys()))\r\n",
        "                while title == new_title:\r\n",
        "                    new_title =  np.random.choice(list(self.uniq_titles.keys()))\r\n",
        "                passage = np.random.choice((self.df_bert[self.df_bert[\"title\"] == title])[\"passage\"].unique())\r\n",
        "                passage_id = np.random.choice(self.uniq_passages[passage])\r\n",
        "                id.append(passage_id)\r\n",
        "                \r\n",
        "        p = self.df['passage'].loc[id].tolist()\r\n",
        "        q = self.df['question'].loc[id].tolist()\r\n",
        "\r\n",
        "        return (np.stack(p), np.stack(q)), np.identity(self.batch_size)\r\n",
        "        '''\r\n",
        "        attention_mask_q = np.stack(q)\r\n",
        "        attention_mask_q[attention_mask_q != 0] = 1\r\n",
        "        attention_mask_p = np.stack(p)\r\n",
        "        attention_mask_p[attention_mask_p != 0] = 1\r\n",
        "        # if len(p) == 0 or len(q) == 0:\r\n",
        "        #     return ([], []), []\r\n",
        "\r\n",
        "        # original = df_bert.loc[self.df.index]\r\n",
        "        # unique_passage = df_bert.loc[self.df.index]['passage'].unique()\r\n",
        "        # print(unique_passage)\r\n",
        "        notp = []\r\n",
        "        for index in range(idx * self.batch_size,(idx + 1) * self.batch_size):\r\n",
        "            title = self.df[\"title\"].iloc[index]\r\n",
        "            passage = self.df[\"passage\"].iloc[index]\r\n",
        "            group = self.groups[title]\r\n",
        "            new_group = []\r\n",
        "            for id in group:\r\n",
        "                if self.df[\"passage\"][id] != passage:\r\n",
        "                    new_group.append(id)\r\n",
        "            notp.append(self.df[\"passage\"][np.random.choice(new_group)])\r\n",
        "        #print(f\"notp: {len(notp)}\")\r\n",
        "        #not_p = groups[]\r\n",
        "        # DA SISTEMARE; CI POTREBBERO ESSERE ANCORA I PASSAGGI GIUSTI PERCHÃ¨ SONO RIPETUTI\r\n",
        "        all_not_p = list(range(0,idx * self.batch_size)) + list(range((idx + 1) * self.batch_size, len(self.df)))\r\n",
        "        #print(all_not_p)\r\n",
        "        rnd = np.random.choice(all_not_p, self.batch_size)                                #####################################################################################################\r\n",
        "        #print(f\"rnd is {rnd}\")\r\n",
        "        #notp = self.df['passage'].iloc[rnd].tolist()\r\n",
        "        attention_mask_not_p = np.stack(notp)\r\n",
        "        attention_mask_not_p[attention_mask_not_p != 0] = 1\r\n",
        "        #print(f\"notp is {notp}\")\r\n",
        "        y = half*[1]+half*[0]\r\n",
        "        #print(np.stack(p+notp))\r\n",
        "        return (np.stack(p+notp),np.vstack((attention_mask_p,attention_mask_not_p)), np.stack(q+q),np.vstack((attention_mask_q,attention_mask_q))), np.array(y)\r\n",
        "        #y = half*[1]+half*[1]\r\n",
        "        #return (np.stack(p+p),np.vstack((attention_mask_p,attention_mask_p)), np.stack(q+q),np.vstack((attention_mask_q,attention_mask_q))), np.array(y)\r\n",
        "        '''\r\n",
        "split_value = 0.1 \r\n",
        "val_dim = int(len(df_bert_preprocessed['title'].unique()) * split_value)\r\n",
        "val_titles = np.random.choice(df_bert_preprocessed['title'].unique(), size=val_dim, replace=False)\r\n",
        "\r\n",
        "df_bert_val = df_bert_preprocessed[df_bert_preprocessed['title'].isin(val_titles)]\r\n",
        "df_bert_train = df_bert_preprocessed[~(df_bert_preprocessed['title'].isin(val_titles))]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMy65yyBp-78",
        "outputId": "a8c7ca40-9a63-4bf5-ca45-e247b6859de4"
      },
      "source": [
        "seq_train = IRDataset(df_bert_train, 16)\r\n",
        "seq_train.__getitem__(0)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[ 101, 2006, 2336, ...,    0,    0,    0],\n",
              "         [ 101, 2006, 2089, ...,    0,    0,    0],\n",
              "         [ 101, 3237, 3580, ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101, 1996, 8372, ...,    0,    0,    0],\n",
              "         [ 101, 2348, 1996, ...,    0,    0,    0],\n",
              "         [ 101, 2116, 5343, ...,    0,    0,    0]]),\n",
              "  array([[ 101, 2073, 2020, ...,    0,    0,    0],\n",
              "         [ 101, 2043, 2106, ...,    0,    0,    0],\n",
              "         [ 101, 2129, 2116, ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101, 2129, 2146, ...,    0,    0,    0],\n",
              "         [ 101, 2054, 2231, ...,    0,    0,    0],\n",
              "         [ 101, 2054, 2533, ...,    0,    0,    0]])),\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwVwRBxzKwep",
        "outputId": "5efd06ce-fef9-44ba-8d96-035f06fe2a46"
      },
      "source": [
        "#@title model definition { form-width: \"25%\" }\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import cosine_similarity, MSE, mae\n",
        "\n",
        "input_passage_ids = tf.keras.layers.Input(batch_input_shape=(16,max_seq_length,), dtype=tf.int32, name='input_passage_ids')\n",
        "input_question_ids = tf.keras.layers.Input(batch_input_shape=(16,max_seq_length,), dtype=tf.int32, name='input_question_ids')\n",
        "\n",
        "bert_hf_layer = transformers.TFElectraModel.from_pretrained(pretrained_model_str)\n",
        "\n",
        "passage_encoding = bert_hf_layer(input_ids=[input_passage_ids]).last_hidden_state[:,0]\n",
        "question_encoding = bert_hf_layer(input_ids=[input_question_ids]).last_hidden_state[:,0]\n",
        "\n",
        "densep = tf.keras.layers.Dense(256)\n",
        "denseq = tf.keras.layers.Dense(256)\n",
        "\n",
        "outp = densep(passage_encoding)\n",
        "outq = denseq(question_encoding)\n",
        "\n",
        "#dot = tf.keras.layers.Dot((0,0))\n",
        "outdot = tf.tensordot(outp, outq, axes=(1,1))\n",
        "\n",
        "softmax = tf.keras.layers.Softmax(axis=0)\n",
        "output = softmax(outdot)\n",
        "\n",
        "model = keras.Model(inputs=[input_passage_ids, input_question_ids], \n",
        "                    outputs=output,\n",
        "                    name=\"BERT_IR\")\n",
        "\n",
        "model.summary(line_length=150)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at google/electra-small-discriminator were not used when initializing TFElectraModel: ['discriminator_predictions']\n",
            "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-small-discriminator.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Model: \"BERT_IR\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
            "======================================================================================================================================================\n",
            "input_passage_ids (InputLayer)                   [(16, 512)]                      0                                                                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "input_question_ids (InputLayer)                  [(16, 512)]                      0                                                                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf_electra_model (TFElectraModel)                TFBaseModelOutput(last_hidden_st 13483008          input_passage_ids[0][0]                           \n",
            "                                                                                                    input_question_ids[0][0]                          \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (SlicingOpLambda)       (16, 256)                        0                 tf_electra_model[0][0]                            \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (SlicingOpLambda)     (16, 256)                        0                 tf_electra_model[1][0]                            \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense (Dense)                                    (16, 256)                        65792             tf.__operators__.getitem[0][0]                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_1 (Dense)                                  (16, 256)                        65792             tf.__operators__.getitem_1[0][0]                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf.tensordot (TFOpLambda)                        (16, 16)                         0                 dense[0][0]                                       \n",
            "                                                                                                    dense_1[0][0]                                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "softmax (Softmax)                                (16, 16)                         0                 tf.tensordot[0][0]                                \n",
            "======================================================================================================================================================\n",
            "Total params: 13,614,592\n",
            "Trainable params: 13,614,592\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "LaYw_ZnZmflK",
        "outputId": "25d5ec7b-a3b6-4b2a-c4ab-db70e3489cfd"
      },
      "source": [
        "#@title train { form-width: \"25%\" }\r\n",
        "\r\n",
        "from transformers.optimization_tf import AdamWeightDecay\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "\r\n",
        "batch_size = 16\r\n",
        "epochs = 200\r\n",
        "\r\n",
        "seq_train = IRDataset(df_bert_train, batch_size)\r\n",
        "seq_val = IRDataset(df_bert_val, batch_size)\r\n",
        "\r\n",
        "saveDir = os.path.join(os.getcwd(), 'saved_models')\r\n",
        "if not os.path.isdir(saveDir):\r\n",
        "    os.makedirs(saveDir)\r\n",
        "chkpt = saveDir + '/squad_check.hdf5'\r\n",
        "\r\n",
        "es_cb = EarlyStopping(monitor='val_loss', patience=5,verbose=1, mode='auto', restore_best_weights = True)\r\n",
        "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, \r\n",
        "                        save_best_only=True, mode='auto', \r\n",
        "                        save_weights_only=True)\r\n",
        "callbacks = [es_cb, cp_cb]\r\n",
        "\r\n",
        "ENABLE_WANDB = False        #@param {type:\"boolean\"}\r\n",
        "wandb_experiment_name = \"electra+dense\"  #@param {type: \"string\"}\r\n",
        "if ENABLE_WANDB:\r\n",
        "    !pip install wandb > /dev/null\r\n",
        "    !wandb login\r\n",
        "    import wandb\r\n",
        "    from wandb.keras import WandbCallback\r\n",
        "    wandb.init(project=\"IR\", name=wandb_experiment_name)\r\n",
        "    wandb.config.batch_size = batch_size\r\n",
        "    wandb.config.epochs = epochs\r\n",
        "    callbacks.append(WandbCallback(log_batch_frequency=10,\r\n",
        "                                   save_weights_only=True))\r\n",
        "\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "optimizer = AdamWeightDecay(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\r\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics = \"accuracy\")\r\n",
        "history = model.fit(seq_train, epochs=epochs,\r\n",
        "                    callbacks=callbacks, \r\n",
        "                    validation_data=seq_val,\r\n",
        "                    batch_size=batch_size)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "398/398 [==============================] - ETA: 0s - loss: 3.5140 - accuracy: 0.0682WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "398/398 [==============================] - 367s 888ms/step - loss: 3.5132 - accuracy: 0.0682 - val_loss: 2.7722 - val_accuracy: 0.0824\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.77223, saving model to /content/saved_models/squad_check.hdf5\n",
            "Epoch 2/200\n",
            "398/398 [==============================] - 356s 896ms/step - loss: 2.9340 - accuracy: 0.0612 - val_loss: 2.7724 - val_accuracy: 0.0767\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 2.77223\n",
            "Epoch 3/200\n",
            "398/398 [==============================] - 356s 896ms/step - loss: 2.8668 - accuracy: 0.0609 - val_loss: 2.7724 - val_accuracy: 0.0696\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 2.77223\n",
            "Epoch 4/200\n",
            "398/398 [==============================] - 356s 895ms/step - loss: 2.8478 - accuracy: 0.0676 - val_loss: 2.7726 - val_accuracy: 0.0540\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2.77223\n",
            "Epoch 5/200\n",
            " 60/398 [===>..........................] - ETA: 4:52 - loss: 2.8576 - accuracy: 0.0396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-2cb8ab629062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     batch_size=batch_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpH1ADf0LrKC",
        "outputId": "0a2930ae-b1cd-4cbf-bd85-3fab45a63a72"
      },
      "source": [
        "#@title inference model { form-width: \"25%\" }\r\n",
        "\r\n",
        "model.load_weights('model-best.h5')\r\n",
        "bert_hf_layer.set_weights(model.layers[2].get_weights())\r\n",
        "densep.set_weights(model.layers[5].get_weights())\r\n",
        "denseq.set_weights(model.layers[6].get_weights())\r\n",
        "\r\n",
        "input_txt_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32)\r\n",
        "output = bert_hf_layer(input_ids=input_txt_ids).last_hidden_state[:,0]\r\n",
        "outp = densep(output)\r\n",
        "passage_encoder = keras.Model(inputs=input_txt_ids, outputs=outp)\r\n",
        "outq = denseq(output)\r\n",
        "question_encoder = keras.Model(inputs=input_txt_ids, outputs=outq)\r\n",
        "\r\n",
        "encoded_val_passage = np.zeros((len(df_bert_val), 256))\r\n",
        "encoded_val_question = np.zeros((len(df_bert_val), 256))\r\n",
        "passages = np.stack(df_bert_val['passage'])\r\n",
        "questions = np.stack(df_bert_val['question'])\r\n",
        "\r\n",
        "for i in tqdm(range(len(df_bert_val)//batch_size)):\r\n",
        "    encoded_val_passage[i*batch_size : (i+1)*batch_size] = passage_encoder(passages[i*batch_size : (i+1)*batch_size])\r\n",
        "    encoded_val_question[i*batch_size : (i+1)*batch_size] = question_encoder(questions[i*batch_size : (i+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [01:03<00:00,  7.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21bEK6SuLRk2",
        "outputId": "272686c6-3211-4665-d2c2-5b2a7c95ff78"
      },
      "source": [
        "#@title kNN cosine similarity (don't work because the net is trained with dot product) { form-width: \"25%\" }\r\n",
        "\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "from sklearn.neighbors import NearestNeighbors\r\n",
        "\r\n",
        "start=985\r\n",
        "size=16\r\n",
        "\r\n",
        "k=1\r\n",
        "tree = NearestNeighbors(n_neighbors=k, metric='cosine')\r\n",
        "tree.fit(encoded_val_passage[start:start+size])\r\n",
        "\r\n",
        "results = tree.kneighbors(encoded_val_question[start:start+size], n_neighbors=k, return_distance=False)\r\n",
        "\r\n",
        "ok=0\r\n",
        "for i in range(len(results)):\r\n",
        "    for j in range(k):\r\n",
        "        if np.array_equal(passages[results[i,j]], passages[i]):\r\n",
        "            ok+=1\r\n",
        "\r\n",
        "ok/len(results)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "uwBfogVczJud",
        "outputId": "9f175fad-bbd4-43f4-d0f8-dcf743c828df"
      },
      "source": [
        "#@title argmax evaluation and plot { form-width: \"25%\" }\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "a = tf.keras.layers.Input(shape=(256,), dtype=tf.float32)\r\n",
        "b = tf.keras.layers.Input(shape=(256,), dtype=tf.float32)\r\n",
        "outdot = tf.tensordot(a, b, axes=(1,1))\r\n",
        "softmax = tf.keras.layers.Softmax(axis=0)\r\n",
        "output = softmax(outdot)\r\n",
        "classifier = keras.Model(inputs=[a,b], outputs=output)\r\n",
        "\r\n",
        "start=985\r\n",
        "size=16\r\n",
        "\r\n",
        "pred = classifier.predict((encoded_val_passage[start:start+size], encoded_val_question[start:start+size]), \r\n",
        "                          batch_size=size)\r\n",
        "\r\n",
        "#### plot\r\n",
        "fig = plt.figure(figsize=(10, 6))\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "ax.set_title('colorMap')\r\n",
        "plt.imshow(pred)\r\n",
        "ax.set_aspect('equal')\r\n",
        "cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\r\n",
        "cax.get_xaxis().set_visible(False)\r\n",
        "cax.get_yaxis().set_visible(False)\r\n",
        "cax.patch.set_alpha(0)\r\n",
        "cax.set_frame_on(False)\r\n",
        "plt.colorbar(orientation='vertical')\r\n",
        "plt.show()\r\n",
        "####\r\n",
        "\r\n",
        "pred = tf.argmax(pred, axis=1)\r\n",
        "\r\n",
        "ok=0\r\n",
        "for i in range(len(pred)):\r\n",
        "    if np.array_equal(passages[pred[i]], passages[i]):\r\n",
        "        ok+=1\r\n",
        "\r\n",
        "ok/len(pred)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff83d3fc200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJSpeKm_jsmO"
      },
      "source": [
        "!pip3 install wikipedia-api\r\n",
        "\r\n",
        "import wikipediaapi\r\n",
        "wiki_wiki = wikipediaapi.Wikipedia('en')\r\n",
        "cat = wiki_wiki.page(\"Category:Physics\")\r\n",
        "print(\"Category members: Category:Physics\")\r\n",
        "for p in cat.categorymembers.values():\r\n",
        "  if p.namespace == wikipediaapi.Namespace.CATEGORY:\r\n",
        "    # it is category, so you have to make decision\r\n",
        "    # if you want to fetch also text from pages that belong\r\n",
        "    # to this category\r\n",
        "    print(p)\r\n",
        "  elif p.namespace == wikipediaapi.Namespace.MAIN:\r\n",
        "    # it is page => we can get text\r\n",
        "    print(p)\r\n",
        "    print(p.text)\r\n",
        "\r\n",
        "def print_categorymembers(categorymembers, level=0, max_level=3):\r\n",
        "        for c in categorymembers.values():\r\n",
        "            print(\"%s: %s (ns: %d)\" % (\"*\" * (level + 1), c.title, c.ns))\r\n",
        "            if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level:\r\n",
        "                print_categorymembers(c.categorymembers, level=level + 1, max_level=max_level)\r\n",
        "\r\n",
        "cat = wiki_wiki.page(\"Category:Artificial intelligence\")\r\n",
        "print_categorymembers(cat.categorymembers)\r\n",
        "\r\n",
        "wiki_wiki = wikipediaapi.Wikipedia('en')\r\n",
        "\r\n",
        "page_py = wiki_wiki.page('Python_(programming_language)')\r\n",
        "print(page_py.text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}